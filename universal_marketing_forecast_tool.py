#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –±—é–¥–∂–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
–í–∫–ª—é—á–∞–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –±—é–¥–∂–µ—Ç–∞
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Scikit-learn –º–æ–¥–µ–ª–∏
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Prophet
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False

import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json
from typing import Dict, List, Tuple, Optional, Any

class UniversalMarketingForecastTool:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.df = None
        self.config = {}
        self.channel_dependencies = {}
        self.cascade_config = {}
        self.models = {}
        self.forecasts = {}
        self.simulation_results = {}
        
    def setup_configuration(self, config_file: str = None, config_dict: Dict = None):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞"""
        print("üîß –ù–ê–°–¢–†–û–ô–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò –ò–ù–°–¢–†–£–ú–ï–ù–¢–ê:")
        
        if config_file:
            with open(config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        elif config_dict:
            self.config = config_dict
        else:
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
            self.config = {
                "time_fields": {
                    "year": "year",
                    "month": "month"
                },
                "dimensions": {
                    "region": "region_to",
                    "subdivision": "subdivision", 
                    "category": "category"
                },
                "metrics": {
                    "revenue": "revenue_total",
                    "traffic": "traffic_total",
                    "transactions": "transacitons_total",
                    "ads_cost": "ads_cost",
                    "first_traffic": "first_traffic",
                    "repeat_traffic": "repeat_traffic",
                    "first_transactions": "first_transactions",
                    "repeat_transactions": "repeat_transactions"
                },
                "channels": {
                    "paid": {
                        "is_paid": True,
                        "traffic_fields": ["first_traffic", "repeat_traffic"],
                        "budget_field": "ads_cost",
                        "conversion_fields": ["first_transactions", "repeat_transactions"]
                    },
                    "organic": {
                        "is_paid": False,
                        "traffic_fields": ["first_traffic", "repeat_traffic"],
                        "budget_field": None,
                        "conversion_fields": ["first_transactions", "repeat_transactions"]
                    }
                },
                "cascade": {
                    "enabled": True,
                    "levels": ["region", "subdivision", "category"],
                    "outlier_threshold": 2.0,
                    "missing_value_strategy": "cascade_up"
                },
                "dependencies": {
                    "ads_cost_to_traffic": {
                        "enabled": True,
                        "paid_channels_only": True,
                        "cross_channel_influence": 0.1
                    }
                }
            }
        
        print("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        self._print_config_summary()
    
    def _print_config_summary(self):
        """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        print(f"\nüìã –°–í–û–î–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò:")
        print(f"  –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è: {list(self.config['time_fields'].values())}")
        print(f"  –ò–∑–º–µ—Ä–µ–Ω–∏—è: {list(self.config['dimensions'].values())}")
        print(f"  –ú–µ—Ç—Ä–∏–∫–∏: {list(self.config['metrics'].values())}")
        print(f"  –ö–∞–Ω–∞–ª—ã: {list(self.config['channels'].keys())}")
        print(f"  –ö–∞—Å–∫–∞–¥: {'–í–∫–ª—é—á–µ–Ω' if self.config['cascade']['enabled'] else '–û—Ç–∫–ª—é—á–µ–Ω'}")
        print(f"  –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {'–í–∫–ª—é—á–µ–Ω—ã' if self.config['dependencies']['ads_cost_to_traffic']['enabled'] else '–û—Ç–∫–ª—é—á–µ–Ω—ã'}")
    
    def load_data(self, csv_file: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\nüìÅ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ò–ó {csv_file}:")
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        separators = [',', ';', '\t', '|']
        for sep in separators:
            try:
                self.df = pd.read_csv(csv_file, sep=sep)
                if len(self.df.columns) > 1:
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}': {len(self.df)} –∑–∞–ø–∏—Å–µ–π, {len(self.df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                    break
            except:
                continue
        
        if self.df is None or len(self.df.columns) <= 1:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º")
            return False
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self._clean_data()
        return True
    
    def _clean_data(self):
        """–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\nüßπ –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•:")
        
        initial_count = len(self.df)
        
        # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
        for field in self.config['time_fields'].values():
            if field in self.df.columns:
                self.df[field] = pd.to_numeric(self.df[field], errors='coerce')
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        time_cols = list(self.config['time_fields'].values())
        self.df = self.df.dropna(subset=time_cols)
        
        # –û—á–∏—Å—Ç–∫–∞ –º–µ—Ç—Ä–∏–∫
        for metric in self.config['metrics'].values():
            if metric in self.df.columns:
                self.df[metric] = self.df[metric].astype(str).str.replace(',', '').str.replace(' ', '')
                self.df[metric] = pd.to_numeric(self.df[metric], errors='coerce')
                self.df[metric] = self.df[metric].fillna(0)
        
        print(f"  –£–¥–∞–ª–µ–Ω–æ {initial_count - len(self.df)} –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        print(f"  –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(self.df)} –∑–∞–ø–∏—Å–µ–π")
    
    def analyze_channel_dependencies(self):
        """–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏"""
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô –ú–ï–ñ–î–£ –ö–ê–ù–ê–õ–ê–ú–ò:")
        
        if not self.config['dependencies']['ads_cost_to_traffic']['enabled']:
            print("  ‚ö†Ô∏è  –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–ª–∏—è–Ω–∏–µ ads_cost –Ω–∞ —Ç—Ä–∞—Ñ–∏–∫
        ads_cost_field = self.config['metrics']['ads_cost']
        traffic_fields = ['first_traffic', 'repeat_traffic']
        
        if ads_cost_field not in self.df.columns:
            print(f"  ‚ùå –ü–æ–ª–µ {ads_cost_field} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö")
            return
        
        print(f"\n  üìä –í–õ–ò–Ø–ù–ò–ï {ads_cost_field} –ù–ê –¢–†–ê–§–ò–ö:")
        
        for traffic_field in traffic_fields:
            if traffic_field in self.df.columns:
                # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è
                correlation = self.df[ads_cost_field].corr(self.df[traffic_field])
                print(f"    {traffic_field}: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è = {correlation:.3f}")
                
                # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞–Ω–∞–ª–∞–º
                if 'is_paid' in self.df.columns:
                    paid_corr = self.df[self.df['is_paid'] == True][ads_cost_field].corr(
                        self.df[self.df['is_paid'] == True][traffic_field]
                    )
                    organic_corr = self.df[self.df['is_paid'] == False][ads_cost_field].corr(
                        self.df[self.df['is_paid'] == False][traffic_field]
                    )
                    print(f"      –ü–ª–∞—Ç–Ω—ã–µ –∫–∞–Ω–∞–ª—ã: {paid_corr:.3f}")
                    print(f"      –û—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ –∫–∞–Ω–∞–ª—ã: {organic_corr:.3f}")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
                self.channel_dependencies[traffic_field] = {
                    'ads_cost_correlation': correlation,
                    'paid_correlation': paid_corr if 'is_paid' in self.df.columns else None,
                    'organic_correlation': organic_corr if 'is_paid' in self.df.columns else None
                }
    
    def build_cascade_forecast(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞—Å–∫–∞–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
        print(f"\nüèóÔ∏è –ü–û–°–¢–†–û–ï–ù–ò–ï –ö–ê–°–ö–ê–î–ù–û–ì–û –ü–†–û–ì–ù–û–ó–ê:")
        
        if not self.config['cascade']['enabled']:
            print("  ‚ö†Ô∏è  –ö–∞—Å–∫–∞–¥–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            return
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —É—Ä–æ–≤–Ω—è–º –∫–∞—Å–∫–∞–¥–∞
        cascade_levels = self.config['cascade']['levels']
        time_fields = list(self.config['time_fields'].values())
        
        print(f"  üìä –ê–ì–†–ï–ì–ê–¶–ò–Ø –ü–û –£–†–û–í–ù–Ø–ú –ö–ê–°–ö–ê–î–ê:")
        
        for level in cascade_levels:
            if level in self.config['dimensions']:
                dimension_field = self.config['dimensions'][level]
                if dimension_field in self.df.columns:
                    print(f"    –£—Ä–æ–≤–µ–Ω—å: {level} ({dimension_field})")
                    
                    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                    agg_data = self.df.groupby(time_fields + [dimension_field]).agg({
                        metric: 'sum' for metric in self.config['metrics'].values() 
                        if metric in self.df.columns
                    }).reset_index()
                    
                    print(f"      –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–æ {len(agg_data)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —ç—Ç–æ–º —É—Ä–æ–≤–Ω–µ
                    self._analyze_level_stability(agg_data, level, dimension_field)
    
    def _analyze_level_stability(self, data: pd.DataFrame, level: str, dimension_field: str):
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Ä–æ–≤–Ω–µ –∫–∞—Å–∫–∞–¥–∞"""
        print(f"      üîç –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —É—Ä–æ–≤–Ω—è {level}:")
        
        revenue_field = self.config['metrics']['revenue']
        if revenue_field not in data.columns:
            return
        
        for dimension_value in data[dimension_field].unique():
            dimension_data = data[data[dimension_field] == dimension_value].copy()
            
            if len(dimension_data) > 6:  # –ú–∏–Ω–∏–º—É–º 6 –º–µ—Å—è—Ü–µ–≤ –¥–∞–Ω–Ω—ã—Ö
                revenue_values = dimension_data[revenue_field].values
                
                # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
                cv = np.std(revenue_values) / np.mean(revenue_values) if np.mean(revenue_values) > 0 else 0
                
                # –¢—Ä–µ–Ω–¥
                time_index = np.arange(len(revenue_values))
                trend_slope = np.polyfit(time_index, revenue_values, 1)[0]
                trend_strength = abs(trend_slope) / np.mean(revenue_values) if np.mean(revenue_values) > 0 else 0
                
                # –û—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                stability_score = (1 - min(cv, 1)) * 0.5 + (1 - min(trend_strength, 1)) * 0.5
                
                print(f"        {dimension_value}: —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å = {stability_score:.3f}")
    
    def build_channel_models(self):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤"""
        print(f"\nü§ñ –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–õ–Ø –ö–ê–ù–ê–õ–û–í:")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        train_data = self._prepare_training_data()
        
        # –°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞
        for channel_name, channel_config in self.config['channels'].items():
            print(f"\n  üìä –ö–∞–Ω–∞–ª: {channel_name}")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–∞–Ω–∞–ª—É
            if 'is_paid' in self.df.columns:
                if channel_config['is_paid']:
                    channel_data = train_data[train_data['is_paid'] == True].copy()
                else:
                    channel_data = train_data[train_data['is_paid'] == False].copy()
            else:
                channel_data = train_data.copy()
            
            if len(channel_data) == 0:
                print(f"    ‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–Ω–∞–ª–∞ {channel_name}")
                continue
            
            # –°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫ –∫–∞–Ω–∞–ª–∞
            channel_models = {}
            
            for metric_name, metric_field in self.config['metrics'].items():
                if metric_field in channel_data.columns:
                    print(f"    üîß –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {metric_name} ({metric_field})")
                    
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                    features = self._prepare_features(channel_data)
                    target = channel_data[metric_field]
                    
                    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
                    model = self._train_model(features, target, metric_name)
                    
                    if model:
                        channel_models[metric_name] = model
                        print(f"      ‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: R¬≤ = {model['r2']:.3f}")
            
            self.models[channel_name] = channel_models
    
    def _prepare_training_data(self) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ –∞–≤–≥—É—Å—Ç–∞ 2025 –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        train_mask = (
            (self.df['year'] < 2025) | 
            ((self.df['year'] == 2025) & (self.df['month'] <= 8))
        )
        return self.df[train_mask].copy()
    
    def _prepare_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏"""
        features_df = data.copy()
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if 'year' in features_df.columns and 'month' in features_df.columns:
            features_df['time_index'] = (features_df['year'] - features_df['year'].min()) * 12 + (features_df['month'] - 1)
            features_df['month_sin'] = np.sin(2 * np.pi * features_df['month'] / 12)
            features_df['month_cos'] = np.cos(2 * np.pi * features_df['month'] / 12)
            
            # –ö–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            features_df['quarter'] = ((features_df['month'] - 1) // 3) + 1
            for q in range(1, 5):
                features_df[f'q{q}'] = (features_df['quarter'] == q).astype(int)
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        for dim_name, dim_field in self.config['dimensions'].items():
            if dim_field in features_df.columns:
                le = LabelEncoder()
                features_df[f'{dim_name}_encoded'] = le.fit_transform(features_df[dim_field].astype(str))
        
        return features_df
    
    def _train_model(self, features: pd.DataFrame, target: pd.Series, metric_name: str) -> Optional[Dict]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        try:
            # –í—ã–±–∏—Ä–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            numeric_features = features.select_dtypes(include=[np.number]).columns.tolist()
            X = features[numeric_features].fillna(0)
            y = target.fillna(0)
            
            if len(X) == 0 or len(y) == 0:
                return None
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # –û–±—É—á–µ–Ω–∏–µ Random Forest
            model = RandomForestRegressor(n_estimators=100, random_state=42)
            model.fit(X_scaled, y)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            y_pred = model.predict(X_scaled)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            r2 = r2_score(y, y_pred)
            mae = mean_absolute_error(y, y_pred)
            
            return {
                'model': model,
                'scaler': scaler,
                'features': numeric_features,
                'r2': r2,
                'mae': mae
            }
            
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞ –≤ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            return None
    
    def create_forecast(self, forecast_periods: int = 16):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
        print(f"\nüîÆ –°–û–ó–î–ê–ù–ò–ï –ü–†–û–ì–ù–û–ó–ê –ù–ê {forecast_periods} –ü–ï–†–ò–û–î–û–í:")
        
        if not self.models:
            print("‚ùå –ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
            return
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞
        for channel_name, channel_models in self.models.items():
            print(f"\n  üìä –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–Ω–∞–ª–∞: {channel_name}")
            
            channel_forecast = {}
            
            for metric_name, model_info in channel_models.items():
                print(f"    üîÆ –ü—Ä–æ–≥–Ω–æ–∑ {metric_name}")
                
                # –°–æ–∑–¥–∞–µ–º –±—É–¥—É—â–∏–µ –ø–µ—Ä–∏–æ–¥—ã
                future_data = self._create_future_periods(forecast_periods)
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
                future_features = self._prepare_features(future_data)
                
                # –ü—Ä–æ–≥–Ω–æ–∑
                forecast_values = self._make_prediction(model_info, future_features)
                
                channel_forecast[metric_name] = {
                    'values': forecast_values,
                    'periods': future_data[['year', 'month']].to_dict('records')
                }
                
                total_forecast = np.sum(forecast_values)
                print(f"      –û–±—â–∏–π –ø—Ä–æ–≥–Ω–æ–∑: {total_forecast:,.0f}")
            
            self.forecasts[channel_name] = channel_forecast
    
    def _create_future_periods(self, periods: int) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±—É–¥—É—â–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤"""
        # –ù–∞—á–∏–Ω–∞–µ–º —Å —Å–µ–Ω—Ç—è–±—Ä—è 2025
        start_year, start_month = 2025, 9
        
        periods_data = []
        current_year, current_month = start_year, start_month
        
        for i in range(periods):
            periods_data.append({
                'year': current_year,
                'month': current_month
            })
            
            current_month += 1
            if current_month > 12:
                current_month = 1
                current_year += 1
        
        return pd.DataFrame(periods_data)
    
    def _make_prediction(self, model_info: Dict, features: pd.DataFrame) -> np.ndarray:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
        try:
            # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            model_features = model_info['features']
            X = features[model_features].fillna(0)
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            X_scaled = model_info['scaler'].transform(X)
            
            # –ü—Ä–æ–≥–Ω–æ–∑
            predictions = model_info['model'].predict(X_scaled)
            
            # –£–±–∏—Ä–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            return np.maximum(predictions, 0)
            
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ: {str(e)}")
            return np.zeros(len(features))
    
    def simulate_budget_scenarios(self, budget_scenarios: List[Dict]):
        """–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –±—é–¥–∂–µ—Ç–∞"""
        print(f"\nüéØ –ú–û–î–ï–õ–ò–†–û–í–ê–ù–ò–ï –°–¶–ï–ù–ê–†–ò–ï–í –ë–Æ–î–ñ–ï–¢–ê:")
        
        if not self.forecasts:
            print("‚ùå –ù–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
            return
        
        for i, scenario in enumerate(budget_scenarios):
            print(f"\n  üìä –°—Ü–µ–Ω–∞—Ä–∏–π {i+1}: {scenario.get('name', f'–°—Ü–µ–Ω–∞—Ä–∏–π {i+1}')}")
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞
            modified_forecast = self._apply_budget_changes(scenario)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –¥—Ä—É–≥–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            impact_analysis = self._analyze_budget_impact(scenario, modified_forecast)
            
            self.simulation_results[f"scenario_{i+1}"] = {
                'scenario': scenario,
                'modified_forecast': modified_forecast,
                'impact_analysis': impact_analysis
            }
            
            print(f"    üí∞ –ò–∑–º–µ–Ω–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞: {scenario.get('budget_change', 0):+.1f}%")
            print(f"    üìà –í–ª–∏—è–Ω–∏–µ –Ω–∞ –≤—ã—Ä—É—á–∫—É: {impact_analysis.get('revenue_impact', 0):+.1f}%")
    
    def _apply_budget_changes(self, scenario: Dict) -> Dict:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –±—é–¥–∂–µ—Ç–∞ –∫ –ø—Ä–æ–≥–Ω–æ–∑—É"""
        modified_forecast = {}
        
        for channel_name, channel_forecast in self.forecasts.items():
            modified_channel = {}
            
            for metric_name, metric_forecast in channel_forecast.items():
                values = metric_forecast['values'].copy()
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫ ads_cost
                if metric_name == 'ads_cost' and 'budget_change' in scenario:
                    change_factor = 1 + scenario['budget_change'] / 100
                    values = values * change_factor
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ç—Ä–∞—Ñ–∏–∫
                if metric_name in ['first_traffic', 'repeat_traffic'] and 'budget_change' in scenario:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –∫–∞–Ω–∞–ª–∞–º–∏
                    if metric_name in self.channel_dependencies:
                        correlation = self.channel_dependencies[metric_name]['ads_cost_correlation']
                        if not np.isnan(correlation):
                            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–ª–∏—è–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                            influence_factor = 1 + (scenario['budget_change'] / 100) * abs(correlation) * 0.5
                            values = values * influence_factor
                
                modified_channel[metric_name] = {
                    'values': values,
                    'periods': metric_forecast['periods']
                }
            
            modified_forecast[channel_name] = modified_channel
        
        return modified_forecast
    
    def _analyze_budget_impact(self, scenario: Dict, modified_forecast: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –±—é–¥–∂–µ—Ç–∞"""
        impact_analysis = {}
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –±–∞–∑–æ–≤—ã–º –ø—Ä–æ–≥–Ω–æ–∑–æ–º
        for channel_name in self.forecasts.keys():
            if channel_name in modified_forecast:
                for metric_name in self.forecasts[channel_name].keys():
                    if metric_name in modified_forecast[channel_name]:
                        original = np.sum(self.forecasts[channel_name][metric_name]['values'])
                        modified = np.sum(modified_forecast[channel_name][metric_name]['values'])
                        
                        if original > 0:
                            change_pct = (modified - original) / original * 100
                            impact_analysis[f"{channel_name}_{metric_name}"] = change_pct
        
        # –û–±—â–µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –≤—ã—Ä—É—á–∫—É
        total_original_revenue = 0
        total_modified_revenue = 0
        
        for channel_name in self.forecasts.keys():
            if 'revenue' in self.forecasts[channel_name]:
                total_original_revenue += np.sum(self.forecasts[channel_name]['revenue']['values'])
            if channel_name in modified_forecast and 'revenue' in modified_forecast[channel_name]:
                total_modified_revenue += np.sum(modified_forecast[channel_name]['revenue']['values'])
        
        if total_original_revenue > 0:
            impact_analysis['revenue_impact'] = (total_modified_revenue - total_original_revenue) / total_original_revenue * 100
        
        return impact_analysis
    
    def generate_report(self, output_file: str = 'Marketing_Forecast_Report.txt'):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        print(f"\nüìä –ì–ï–ù–ï–†–ê–¶–ò–Ø –û–¢–ß–ï–¢–ê:")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("–û–¢–ß–ï–¢ –ü–û –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Æ –ú–ê–†–ö–ï–¢–ò–ù–ì–ê\n")
            f.write("=" * 50 + "\n\n")
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
            f.write("–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:\n")
            f.write(f"–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è: {list(self.config['time_fields'].values())}\n")
            f.write(f"–ò–∑–º–µ—Ä–µ–Ω–∏—è: {list(self.config['dimensions'].values())}\n")
            f.write(f"–ú–µ—Ç—Ä–∏–∫–∏: {list(self.config['metrics'].values())}\n")
            f.write(f"–ö–∞–Ω–∞–ª—ã: {list(self.config['channels'].keys())}\n\n")
            
            # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            if self.channel_dependencies:
                f.write("–ó–ê–í–ò–°–ò–ú–û–°–¢–ò –ú–ï–ñ–î–£ –ö–ê–ù–ê–õ–ê–ú–ò:\n")
                for metric, deps in self.channel_dependencies.items():
                    f.write(f"{metric}: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å ads_cost = {deps['ads_cost_correlation']:.3f}\n")
                f.write("\n")
            
            # –ü—Ä–æ–≥–Ω–æ–∑—ã
            if self.forecasts:
                f.write("–ü–†–û–ì–ù–û–ó–´:\n")
                for channel_name, channel_forecast in self.forecasts.items():
                    f.write(f"\n–ö–∞–Ω–∞–ª: {channel_name}\n")
                    for metric_name, metric_forecast in channel_forecast.items():
                        total = np.sum(metric_forecast['values'])
                        f.write(f"  {metric_name}: {total:,.0f}\n")
                f.write("\n")
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è
            if self.simulation_results:
                f.write("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–û–î–ï–õ–ò–†–û–í–ê–ù–ò–Ø:\n")
                for scenario_name, results in self.simulation_results.items():
                    f.write(f"\n{scenario_name}:\n")
                    f.write(f"  –°—Ü–µ–Ω–∞—Ä–∏–π: {results['scenario']}\n")
                    f.write(f"  –í–ª–∏—è–Ω–∏–µ –Ω–∞ –≤—ã—Ä—É—á–∫—É: {results['impact_analysis'].get('revenue_impact', 0):+.1f}%\n")
        
        print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {output_file}")
    
    def save_results(self, output_file: str = 'Marketing_Forecast_Results.csv'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if not self.forecasts:
            print("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–æ–≥–Ω–æ–∑—ã
        all_results = []
        
        for channel_name, channel_forecast in self.forecasts.items():
            for metric_name, metric_forecast in channel_forecast.items():
                for i, (period, value) in enumerate(zip(metric_forecast['periods'], metric_forecast['values'])):
                    all_results.append({
                        'channel': channel_name,
                        'metric': metric_name,
                        'year': period['year'],
                        'month': period['month'],
                        'forecast_value': value
                    })
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
        results_df = pd.DataFrame(all_results)
        results_df.to_csv(output_file, index=False)
        
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_file}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ò–ù–°–¢–†–£–ú–ï–ù–¢ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –ú–ê–†–ö–ï–¢–ò–ù–ì–ê")
    print("=" * 60)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    tool = UniversalMarketingForecastTool()
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    tool.setup_configuration()
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if not tool.load_data('Marketing Budjet Emulation - raw2.csv'):
        return
    
    # –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    tool.analyze_channel_dependencies()
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞—Å–∫–∞–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞
    tool.build_cascade_forecast()
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–∞–Ω–∞–ª–æ–≤
    tool.build_channel_models()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞
    tool.create_forecast()
    
    # –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –±—é–¥–∂–µ—Ç–∞
    budget_scenarios = [
        {'name': '–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞ –Ω–∞ 20%', 'budget_change': 20},
        {'name': '–£–º–µ–Ω—å—à–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞ –Ω–∞ 10%', 'budget_change': -10},
        {'name': '–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞ –Ω–∞ 50%', 'budget_change': 50}
    ]
    tool.simulate_budget_scenarios(budget_scenarios)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    tool.generate_report()
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    tool.save_results()
    
    print(f"\nüéâ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    main()
