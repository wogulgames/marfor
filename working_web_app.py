#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MARFOR - –†–∞–±–æ—á–µ–µ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –∫–∞—Å–∫–∞–¥–Ω—É—é –º–æ–¥–µ–ª—å —Å Random Forest –∏ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
"""

import pandas as pd
import numpy as np
import os
import uuid
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏
from feature_builder import FeatureBuilder
from hierarchy import HierarchyReconciler

def convert_to_json_serializable(obj):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è pandas/numpy –æ–±—ä–µ–∫—Ç–æ–≤ –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ç–∏–ø—ã"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, pd.Series):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_to_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_serializable(item) for item in obj]
    elif pd.isna(obj):
        return None
    else:
        return obj

def calculate_metrics(actual, predicted):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    actual = np.array(actual)
    predicted = np.array(predicted)
    
    # MAE - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
    mae = np.mean(np.abs(actual - predicted))
    
    # RMSE - –∫–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–π –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏
    rmse = np.sqrt(np.mean((actual - predicted) ** 2))
    
    # MAPE - —Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
    # –ò—Å–∫–ª—é—á–∞–µ–º –Ω—É–ª–∏ –∏–∑ —Ä–∞—Å—á–µ—Ç–∞ MAPE —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å inf
    mask = actual != 0
    if mask.sum() > 0:
        mape = np.mean(np.abs((actual[mask] - predicted[mask]) / actual[mask])) * 100
    else:
        mape = 0.0  # –ï—Å–ª–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω—É–ª–∏
    
    # –ó–∞–º–µ–Ω—è–µ–º inf –∏ nan –Ω–∞ 0
    mae = 0.0 if (np.isnan(mae) or np.isinf(mae)) else float(mae)
    rmse = 0.0 if (np.isnan(rmse) or np.isinf(rmse)) else float(rmse)
    mape = 0.0 if (np.isnan(mape) or np.isinf(mape)) else float(mape)
    
    return {
        'mae': mae,
        'rmse': rmse,
        'mape': mape
    }

def train_arima_model(train_df, test_df, metric):
    """–û–±—É—á–µ–Ω–∏–µ ARIMA –º–æ–¥–µ–ª–∏"""
    try:
        from statsmodels.tsa.arima.model import ARIMA
        
        print(f"   ARIMA: –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ - {len(train_df)} –ø–µ—Ä–∏–æ–¥–æ–≤")
        print(f"   ARIMA: –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ - {len(test_df)} –ø–µ—Ä–∏–æ–¥–æ–≤")
        
        # –û–±—É—á–∞–µ–º –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        model = ARIMA(train_df[metric], order=(1, 1, 1))
        model_fit = model.fit()
        
        print(f"   ARIMA: –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
        
        # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é –≤—ã–±–æ—Ä–∫—É
        forecast = model_fit.forecast(steps=len(test_df))
        
        print(f"   ARIMA: –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å—Ç—Ä–æ–µ–Ω")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics = calculate_metrics(test_df[metric].values, forecast.values)
        
        print(f"   ARIMA: –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã—á–∏—Å–ª–µ–Ω—ã - MAPE: {metrics['mape']:.2f}%")
        
        return {
            'metrics': metrics,
            'validation': {
                'labels': test_df['period'].tolist(),
                'actual': test_df[metric].tolist(),
                'predicted': forecast.tolist()
            }
        }
    except Exception as e:
        print(f"   ‚ùå ARIMA: –û—à–∏–±–∫–∞ - {str(e)}")
        import traceback
        traceback.print_exc()
        raise

def train_prophet_model(train_df, test_df, metric, year_col, month_col):
    """–û–±—É—á–µ–Ω–∏–µ Prophet –º–æ–¥–µ–ª–∏"""
    from prophet import Prophet
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet
    prophet_df = train_df[[year_col, month_col, metric]].copy()
    prophet_df['ds'] = pd.to_datetime(prophet_df[year_col].astype(str) + '-' + 
                                      prophet_df[month_col].astype(str).str.zfill(2) + '-01')
    prophet_df['y'] = prophet_df[metric]
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)
    model.fit(prophet_df[['ds', 'y']])
    
    # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é –≤—ã–±–æ—Ä–∫—É
    future_df = test_df[[year_col, month_col]].copy()
    future_df['ds'] = pd.to_datetime(future_df[year_col].astype(str) + '-' + 
                                     future_df[month_col].astype(str).str.zfill(2) + '-01')
    
    forecast = model.predict(future_df)
    predicted = forecast['yhat'].values
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = calculate_metrics(test_df[metric].values, predicted)
    
    return {
        'metrics': metrics,
        'validation_data': {
            'periods': test_df['period'].tolist(),
            'actual': test_df[metric].tolist(),
            'predicted': predicted.tolist()
        }
    }

def train_random_forest_model(train_df, test_df, metric, year_col, month_col):
    """–û–±—É—á–µ–Ω–∏–µ Random Forest –º–æ–¥–µ–ª–∏ (–±–µ–∑ —Å—Ä–µ–∑–æ–≤)"""
    from sklearn.ensemble import RandomForestRegressor
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X_train = train_df[[year_col, month_col]].values
    y_train = train_df[metric].values
    
    X_test = test_df[[year_col, month_col]].values
    y_test = test_df[metric].values
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    predicted = model.predict(X_test)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = calculate_metrics(y_test, predicted)
    
    return {
        'metrics': metrics,
        'validation': {
            'labels': test_df['period'].tolist(),
            'actual': test_df[metric].tolist(),
            'predicted': predicted.tolist()
        }
    }

def train_random_forest_with_slices(df_agg, metric, year_col, month_col, slice_cols, test_size):
    """–û–±—É—á–µ–Ω–∏–µ Random Forest —Å —É—á–µ—Ç–æ–º —Å—Ä–µ–∑–æ–≤ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import LabelEncoder
    
    print(f"   üå≤ Random Forest: –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ä–µ–∑–∞–º–∏ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏", flush=True)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
    df_model = df_agg.copy()
    df_model['period'] = df_model[year_col].astype(str) + '-' + df_model[month_col].astype(str).str.zfill(2)
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Å—Ä–µ–∑—ã)
    label_encoders = {}
    for col in slice_cols:
        le = LabelEncoder()
        df_model[f'{col}_encoded'] = le.fit_transform(df_model[col].fillna('unknown'))
        label_encoders[col] = le
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏: –≥–æ–¥, –º–µ—Å—è—Ü, –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã
    feature_cols = [year_col, month_col] + [f'{col}_encoded' for col in slice_cols]
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    df_model = df_model.sort_values([year_col, month_col])
    split_index = int(len(df_model) * (1 - test_size))
    
    train_df = df_model[:split_index]
    test_df = df_model[split_index:]
    
    X_train = train_df[feature_cols].values
    y_train = train_df[metric].values
    X_test = test_df[feature_cols].values
    y_test = test_df[metric].values
    
    print(f"      Train: {len(X_train)} —Å—Ç—Ä–æ–∫, Test: {len(X_test)} —Å—Ç—Ä–æ–∫", flush=True)
    print(f"      –ü—Ä–∏–∑–Ω–∞–∫–∏: {feature_cols}", flush=True)
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15)
    model.fit(X_train, y_train)
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    predicted = model.predict(X_test)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    metrics = calculate_metrics(y_test, predicted)
    
    # –î–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    test_df_copy = test_df.copy()
    test_df_copy['predicted'] = predicted
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥—É –∏ —Å—É–º–º–∏—Ä—É–µ–º (–¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞)
    validation_agg = test_df_copy.groupby('period').agg({
        metric: 'sum',
        'predicted': 'sum'
    }).reset_index()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ñ–∞–∫—Ç–∞ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
    
    # –î–æ–±–∞–≤–ª—è–µ–º Quarter –∏ Halfyear –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    if 'Quarter' not in test_df_copy.columns:
        test_df_copy['Quarter'] = test_df_copy[month_col].apply(lambda m: f'Q{(int(m)-1)//3 + 1}')
    if 'Halfyear' not in test_df_copy.columns:
        test_df_copy['Halfyear'] = test_df_copy[month_col].apply(lambda m: 'H1' if int(m) <= 6 else 'H2')
    
    # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    base_cols = [year_col, 'Halfyear', 'Quarter', month_col] + slice_cols
    detailed_validation = test_df_copy[base_cols].copy()
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏ –º–µ—Ç—Ä–∏–∫: —Ñ–∞–∫—Ç –∏ –ø—Ä–æ–≥–Ω–æ–∑
    detailed_validation[f'{metric}_fact'] = test_df_copy[metric]
    detailed_validation[f'{metric}_predicted'] = test_df_copy['predicted']
    
    print(f"   üìä –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: {len(detailed_validation)} —Å—Ç—Ä–æ–∫", flush=True)
    print(f"   üìä –ö–æ–ª–æ–Ω–∫–∏: {list(detailed_validation.columns)}", flush=True)
    print(f"   üìä –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞:", detailed_validation.iloc[0].to_dict() if len(detailed_validation) > 0 else "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö", flush=True)
    
    return {
        'metrics': metrics,
        'validation_data': {
            'periods': validation_agg['period'].tolist(),
            'actual': validation_agg[metric].tolist(),
            'predicted': validation_agg['predicted'].tolist()
        },
        'detailed_validation': detailed_validation.to_dict('records'),  # –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        'slice_cols': slice_cols,  # –ù–∞–∑–≤–∞–Ω–∏—è —Å—Ä–µ–∑–æ–≤
        'model': model,
        'label_encoders': label_encoders,
        'feature_cols': feature_cols
    }

def train_random_forest_hierarchy(df_agg, metric, year_col, month_col, slice_cols, test_size):
    """–û–±—É—á–µ–Ω–∏–µ Random Forest —Å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ–º –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏"""
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.preprocessing import LabelEncoder
    
    print(f"   üå≤üèóÔ∏è Random Forest Hierarchy: –æ–±—É—á–µ–Ω–∏–µ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏", flush=True)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
    df_model = df_agg.copy()
    df_model['period'] = df_model[year_col].astype(str) + '-' + df_model[month_col].astype(str).str.zfill(2)
    
    # –ö–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (—Å—Ä–µ–∑—ã)
    label_encoders = {}
    for col in slice_cols:
        le = LabelEncoder()
        df_model[f'{col}_encoded'] = le.fit_transform(df_model[col].fillna('unknown'))
        label_encoders[col] = le
    
    print(f"   üîß –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...", flush=True)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º FeatureBuilder –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # –í–∞–∂–Ω–æ: —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ
    all_data = []
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
    unique_slices = df_model[slice_cols].drop_duplicates().to_dict('records')
    
    print(f"   üìä –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(unique_slices)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å—Ä–µ–∑–æ–≤", flush=True)
    
    for slice_combination in unique_slices:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        mask = pd.Series([True] * len(df_model))
        for slice_col in slice_cols:
            mask &= (df_model[slice_col] == slice_combination[slice_col])
        
        df_slice = df_model[mask].copy()
        
        if len(df_slice) < 15:  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 15 —Ç–æ—á–µ–∫ –¥–ª—è –ª–∞–≥–æ–≤ –∏ rolling
            continue
        
        # –°—Ç—Ä–æ–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
        fb = FeatureBuilder(df_slice, metric, month_col, year_col)
        df_with_features, _ = fb.build_all_features(categorical_cols=[f'{col}_encoded' for col in slice_cols])
        
        all_data.append(df_with_features)
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    df_enriched = pd.concat(all_data, ignore_index=True)
    
    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(df_enriched)} —Å—Ç—Ä–æ–∫", flush=True)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN (–∏–∑-–∑–∞ –ª–∞–≥–æ–≤ –∏ rolling)
    df_enriched_clean = df_enriched.dropna()
    
    print(f"   üìä –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è NaN: {len(df_enriched_clean)} —Å—Ç—Ä–æ–∫", flush=True)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    exclude_cols = [metric, 'period', 'time_index'] + slice_cols
    feature_cols = [col for col in df_enriched_clean.columns if col not in exclude_cols]
    
    print(f"   üìä –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}", flush=True)
    print(f"   üìä –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {feature_cols[:10]}", flush=True)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    df_enriched_clean = df_enriched_clean.sort_values([year_col, month_col])
    split_index = int(len(df_enriched_clean) * (1 - test_size))
    
    train_df = df_enriched_clean[:split_index]
    test_df = df_enriched_clean[split_index:]
    
    X_train = train_df[feature_cols].values
    y_train = train_df[metric].values
    X_test = test_df[feature_cols].values
    y_test = test_df[metric].values
    
    print(f"      Train: {len(X_train)} —Å—Ç—Ä–æ–∫, Test: {len(X_test)} —Å—Ç—Ä–æ–∫", flush=True)
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    model = RandomForestRegressor(
        n_estimators=200,  # –ë–æ–ª—å—à–µ –¥–µ—Ä–µ–≤—å–µ–≤
        random_state=42,
        n_jobs=-1,
        max_depth=20,  # –ì–ª—É–±–∂–µ
        min_samples_split=5,
        min_samples_leaf=2
    )
    model.fit(X_train, y_train)
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    predicted = model.predict(X_test)
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è
    metrics_before = calculate_metrics(y_test, predicted)
    
    print(f"   üìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–æ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è: MAPE = {metrics_before['mape']:.2f}%", flush=True)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ (bottom-up)
    test_df_copy = test_df.copy()
    test_df_copy['predicted_raw'] = predicted
    
    # –°–æ–∑–¥–∞–µ–º reconciler
    reconciler = HierarchyReconciler(slice_cols, metric)
    
    # Bottom-up —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ
    print(f"   üîº –ü—Ä–∏–º–µ–Ω—è–µ–º bottom-up —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ...", flush=True)
    test_df_copy['predicted'] = predicted  # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
    
    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω–æ–µ bottom-up —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ
    # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –ø–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è
    metrics_after = calculate_metrics(y_test, test_df_copy['predicted'].values)
    
    print(f"   üìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è: MAPE = {metrics_after['mape']:.2f}%", flush=True)
    
    # –î–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    validation_agg = test_df_copy.groupby('period').agg({
        metric: 'sum',
        'predicted': 'sum'
    }).reset_index()
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    if 'Quarter' not in test_df_copy.columns:
        test_df_copy['Quarter'] = test_df_copy[month_col].apply(lambda m: f'Q{(int(m)-1)//3 + 1}')
    if 'Halfyear' not in test_df_copy.columns:
        test_df_copy['Halfyear'] = test_df_copy[month_col].apply(lambda m: 'H1' if int(m) <= 6 else 'H2')
    
    base_cols = [year_col, 'Halfyear', 'Quarter', month_col] + slice_cols
    detailed_validation = test_df_copy[base_cols].copy()
    
    detailed_validation[f'{metric}_fact'] = test_df_copy[metric]
    detailed_validation[f'{metric}_predicted'] = test_df_copy['predicted']
    
    print(f"   üìä –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è: {len(detailed_validation)} —Å—Ç—Ä–æ–∫", flush=True)
    
    return {
        'metrics': metrics_after,
        'validation_data': {
            'periods': validation_agg['period'].tolist(),
            'actual': validation_agg[metric].tolist(),
            'predicted': validation_agg['predicted'].tolist()
        },
        'detailed_validation': detailed_validation.to_dict('records'),
        'slice_cols': slice_cols,
        'model': model,
        'label_encoders': label_encoders,
        'feature_cols': feature_cols,
        'feature_builder': None,  # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–µ
        'metrics_before_reconciliation': metrics_before,
        'reconciliation_improvement': metrics_before['mape'] - metrics_after['mape']
    }

def train_prophet_with_slices(df_agg, metric, year_col, month_col, slice_cols, test_size):
    """–û–±—É—á–µ–Ω–∏–µ Prophet —Å —É—á–µ—Ç–æ–º —Å—Ä–µ–∑–æ–≤ –∫–∞–∫ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–æ–≤"""
    from prophet import Prophet
    
    print(f"   üìà Prophet: –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ä–µ–∑–∞–º–∏ –∫–∞–∫ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–∞–º–∏", flush=True)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
    df_model = df_agg.copy()
    df_model['ds'] = pd.to_datetime(df_model[year_col].astype(str) + '-' + 
                                     df_model[month_col].astype(str).str.zfill(2) + '-01')
    df_model['y'] = df_model[metric]
    
    # One-hot encoding –¥–ª—è —Å—Ä–µ–∑–æ–≤
    df_encoded = pd.get_dummies(df_model, columns=slice_cols, prefix=slice_cols)
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–æ–Ω–∫–∏-—Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã (–≤—Å–µ one-hot encoded –∫–æ–ª–æ–Ω–∫–∏)
    regressor_cols = [col for col in df_encoded.columns if any(col.startswith(f'{sc}_') for sc in slice_cols)]
    
    print(f"      –†–µ–≥—Ä–µ—Å—Å–æ—Ä—ã (—Å—Ä–µ–∑—ã): {len(regressor_cols)} –∫–æ–ª–æ–Ω–æ–∫", flush=True)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/test
    df_encoded = df_encoded.sort_values(['ds'])
    split_index = int(len(df_encoded) * (1 - test_size))
    
    train_df = df_encoded[:split_index]
    test_df = df_encoded[split_index:]
    
    print(f"      Train: {len(train_df)} —Å—Ç—Ä–æ–∫, Test: {len(test_df)} —Å—Ç—Ä–æ–∫", flush=True)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Prophet
    prophet_train = train_df[['ds', 'y'] + regressor_cols].copy()
    prophet_test = test_df[['ds'] + regressor_cols].copy()
    
    # –°–æ–∑–¥–∞–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä—ã
    for reg_col in regressor_cols:
        model.add_regressor(reg_col)
    
    model.fit(prophet_train)
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    forecast = model.predict(prophet_test)
    predicted = forecast['yhat'].values
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    y_test = test_df['y'].values
    metrics = calculate_metrics(y_test, predicted)
    
    # –î–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ - –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º
    test_df_copy = test_df.copy()
    test_df_copy['predicted'] = predicted
    test_df_copy['period'] = test_df_copy['ds'].dt.strftime('%Y-%m')
    
    validation_agg = test_df_copy.groupby('period').agg({
        'y': 'sum',
        'predicted': 'sum'
    }).reset_index()
    
    return {
        'metrics': metrics,
        'validation_data': {
            'periods': validation_agg['period'].tolist(),
            'actual': validation_agg['y'].tolist(),
            'predicted': validation_agg['predicted'].tolist()
        },
        'model': model,
        'regressor_cols': regressor_cols
    }

# –§—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–∞ –±—É–¥—É—â–∏–µ –ø–µ—Ä–∏–æ–¥—ã

def generate_arima_forecast(df_agg, metric, steps):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–º–æ—â—å—é ARIMA"""
    from statsmodels.tsa.arima.model import ARIMA
    
    # –û–±—É—á–∞–µ–º –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    model = ARIMA(df_agg[metric], order=(1, 1, 1))
    model_fit = model.fit()
    
    # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ N —à–∞–≥–æ–≤ –≤–ø–µ—Ä–µ–¥
    forecast = model_fit.forecast(steps=steps)
    
    return forecast.tolist()

def generate_prophet_forecast(df_agg, metric, year_col, month_col, forecast_months):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–º–æ—â—å—é Prophet"""
    from prophet import Prophet
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    prophet_df = df_agg[[year_col, month_col, metric]].copy()
    prophet_df['ds'] = pd.to_datetime(prophet_df[year_col].astype(str) + '-' + 
                                      prophet_df[month_col].astype(str).str.zfill(2) + '-01')
    prophet_df['y'] = prophet_df[metric]
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)
    model.fit(prophet_df[['ds', 'y']])
    
    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    future_dates = []
    for fm in forecast_months:
        date_str = f"{fm['year']}-{str(fm['month']).zfill(2)}-01"
        future_dates.append(date_str)
    
    future_df = pd.DataFrame({'ds': pd.to_datetime(future_dates)})
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    forecast = model.predict(future_df)
    
    return forecast['yhat'].tolist()

def generate_random_forest_forecast(df_agg, metric, year_col, month_col, forecast_months):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–º–æ—â—å—é Random Forest"""
    from sklearn.ensemble import RandomForestRegressor
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X_train = df_agg[[year_col, month_col]].values
    y_train = df_agg[metric].values
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
    X_forecast = np.array([[fm['year'], fm['month']] for fm in forecast_months])
    
    # –ü—Ä–æ–≥–Ω–æ–∑
    predicted = model.predict(X_forecast)
    
    return predicted.tolist()

def generate_random_forest_hierarchy_forecast(df_agg, metric, year_col, month_col, slice_cols, forecast_months, trained_model_data):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–º–æ—â—å—é Random Forest Hierarchy - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏—è)"""
    detailed = generate_random_forest_hierarchy_forecast_detailed(df_agg, metric, year_col, month_col, slice_cols, forecast_months, trained_model_data)
    return [f['predicted'] for f in detailed]

def generate_random_forest_hierarchy_forecast_detailed(df_agg, metric, year_col, month_col, slice_cols, forecast_months, trained_model_data):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –ø–æ–º–æ—â—å—é Random Forest Hierarchy —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏"""
    print(f"\nüå≤üèóÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ Random Forest Hierarchy", flush=True)
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ encoders –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    if not trained_model_data:
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
    
    model = trained_model_data.get('model')
    label_encoders = trained_model_data.get('label_encoders', {})
    feature_cols = trained_model_data.get('feature_cols', [])
    
    if not model or not feature_cols:
        raise ValueError("–ú–æ–¥–µ–ª—å –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    print(f"   üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º {len(feature_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞", flush=True)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ: —Å—Ç—Ä–æ–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
    all_forecasts = []
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
    unique_slices = df_agg[slice_cols].drop_duplicates().to_dict('records')
    
    print(f"   üìä –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è {len(unique_slices)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å—Ä–µ–∑–æ–≤", flush=True)
    
    for slice_combination in unique_slices:
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        mask = pd.Series([True] * len(df_agg))
        for slice_col in slice_cols:
            mask &= (df_agg[slice_col] == slice_combination[slice_col])
        
        df_slice = df_agg[mask].copy()
        
        if len(df_slice) < 15:
            continue
        
        # –ö–æ–¥–∏—Ä—É–µ–º —Å—Ä–µ–∑—ã (–Ω—É–∂–Ω–æ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)
        for slice_col in slice_cols:
            encoded_col = f'{slice_col}_encoded'
            if encoded_col in label_encoders:
                le = label_encoders[encoded_col]
                value = slice_combination[slice_col]
                try:
                    df_slice[encoded_col] = le.transform([value if value in le.classes_ else 'unknown'])[0]
                except:
                    df_slice[encoded_col] = 0
        
        # –°—Ç—Ä–æ–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        fb = FeatureBuilder(df_slice, metric, month_col, year_col)
        df_with_features, _ = fb.build_all_features(categorical_cols=[f'{col}_encoded' for col in slice_cols])
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±—É–¥—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        for fm in forecast_months:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å—Ç—Ä–æ–∫ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –ª–∞–≥–æ–≤ –∏ rolling
            recent_data = df_with_features.tail(15).copy()
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
            forecast_row = {
                year_col: fm['year'],
                month_col: fm['month']
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ä–µ–∑—ã
            for slice_col in slice_cols:
                forecast_row[slice_col] = slice_combination[slice_col]
                encoded_col = f'{slice_col}_encoded'
                if encoded_col in label_encoders:
                    le = label_encoders[encoded_col]
                    value = slice_combination[slice_col]
                    try:
                        forecast_row[encoded_col] = le.transform([value if value in le.classes_ else 'unknown'])[0]
                    except:
                        forecast_row[encoded_col] = 0
            
            # –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
            time_index = (fm['year'] - df_slice[year_col].min()) * 12 + fm['month']
            forecast_row['time_index'] = time_index
            forecast_row['time_index_squared'] = time_index ** 2
            
            # –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            # 1. –°–∏–Ω—É—Å–æ–∏–¥—ã
            forecast_row['month_sin'] = np.sin(2 * np.pi * fm['month'] / 12)
            forecast_row['month_cos'] = np.cos(2 * np.pi * fm['month'] / 12)
            
            # 2. One-hot –¥–ª—è –º–µ—Å—è—Ü–µ–≤
            for month in range(1, 13):
                forecast_row[f'is_month_{month}'] = 1 if fm['month'] == month else 0
            
            # 3. –ü–∏–∫–æ–≤—ã–µ –º–µ—Å—è—Ü—ã
            peak_months = [2, 3, 5, 11, 12]
            forecast_row['is_peak_month'] = 1 if fm['month'] in peak_months else 0
            
            # 4. Q4
            forecast_row['is_q4'] = 1 if fm['month'] >= 10 else 0
            
            # –õ–∞–≥–∏ –∏ rolling - –±–µ—Ä–µ–º –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å
            for col in feature_cols:
                if col not in forecast_row:
                    # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω, –±–µ—Ä–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                    if col in recent_data.columns:
                        forecast_row[col] = recent_data[col].mean()
                    else:
                        forecast_row[col] = 0
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            X_forecast = np.array([[forecast_row.get(col, 0) for col in feature_cols]])
            
            # –ü—Ä–æ–≥–Ω–æ–∑
            predicted_value = model.predict(X_forecast)[0]
            
            all_forecasts.append({
                'year': fm['year'],
                'month': fm['month'],
                **slice_combination,
                'predicted': predicted_value
            })
    
    print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {len(all_forecasts)}", flush=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    return all_forecasts

# Flask
from flask import Flask, render_template, render_template_string, request, jsonify, send_file, redirect
from werkzeug.utils import secure_filename

# Scikit-learn –º–æ–¥–µ–ª–∏
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error
import matplotlib
matplotlib.use('Agg')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º non-interactive backend
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

app = Flask(__name__, static_folder='static')
app.secret_key = 'marfor-working-app-2024'

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤
UPLOAD_FOLDER = 'uploads'
RESULTS_FOLDER = 'results'
ALLOWED_EXTENSIONS = {'csv', 'xlsx', 'xls'}

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['RESULTS_FOLDER'] = RESULTS_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(RESULTS_FOLDER, exist_ok=True)

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

class WorkingForecastApp:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.df = None
        self.session_id = None
        self.forecast_results = {}
        self.data_mapping = {}
        
    def load_data_from_file(self, file_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            if file_path.endswith('.csv'):
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
                separators = [',', ';', '\t', '|']
                for sep in separators:
                    try:
                        self.df = pd.read_csv(file_path, sep=sep, encoding='utf-8')
                        if len(self.df.columns) > 1:
                            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}': {len(self.df)} –∑–∞–ø–∏—Å–µ–π, {len(self.df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                            break
                    except:
                        try:
                            self.df = pd.read_csv(file_path, sep=sep, encoding='cp1251')
                            if len(self.df.columns) > 1:
                                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '{sep}' (cp1251): {len(self.df)} –∑–∞–ø–∏—Å–µ–π, {len(self.df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                                break
                        except:
                            continue
            elif file_path.endswith(('.xlsx', '.xls')):
                self.df = pd.read_excel(file_path)
            
            if self.df is None or len(self.df.columns) <= 1:
                return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º"
            
            # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            self._clean_data()
            return True, f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} –∑–∞–ø–∏—Å–µ–π, {len(self.df.columns)} –∫–æ–ª–æ–Ω–æ–∫"
            
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}"
    
    def _clean_data(self):
        """–û—á–∏—Å—Ç–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\nüßπ –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–•:")
        initial_count = len(self.df)
        
        # –û—á–∏—Å—Ç–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        for col in self.df.columns:
            if self.df[col].dtype == 'object':
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                self.df[col] = self.df[col].astype(str).str.replace(',', '').str.replace(' ', '')
                self.df[col] = pd.to_numeric(self.df[col], errors='ignore')
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –≥–¥–µ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN
        self.df = self.df.dropna(how='all')
        
        print(f"  –£–¥–∞–ª–µ–Ω–æ {initial_count - len(self.df)} –∑–∞–ø–∏—Å–µ–π —Å –ø—É—Å—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
        print(f"  –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(self.df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –ö–û–õ–û–ù–û–ö:")
        for i, col in enumerate(self.df.columns):
            dtype = self.df[col].dtype
            non_null = self.df[col].count()
            print(f"  {i}: {col} ({dtype}) - {non_null} –∑–Ω–∞—á–µ–Ω–∏–π")
    
    def get_data_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is None:
            return None
        
        # –û—á–∏—â–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è JSON
        sample_data = convert_to_json_serializable(self.df.head(5).fillna('').to_dict('records'))
        
        info = {
            'shape': self.df.shape,
            'columns': list(self.df.columns),
            'dtypes': {col: str(dtype) for col, dtype in self.df.dtypes.items()},
            'sample_data': sample_data,
            'missing_values': self.df.isnull().sum().to_dict()
        }
        
        return info
    
    def apply_data_mapping(self, mapping_config):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –º–∞–ø–ø–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö"""
        if self.df is None:
            raise ValueError("–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        
        df = self.df.copy()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–ª–æ–Ω–æ–∫
        columns_to_include = []
        for col_config in mapping_config.get('columns', []):
            if col_config.get('include', True):
                col_name = col_config['name']
                col_type = col_config.get('type', 'auto')
                
                if col_name in df.columns:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤
                    if col_type == 'numeric':
                        df[col_name] = pd.to_numeric(df[col_name], errors='coerce')
                    elif col_type == 'text':
                        df[col_name] = df[col_name].astype(str)
                    elif col_type == 'category':
                        df[col_name] = df[col_name].astype('category')
                    
                    columns_to_include.append(col_name)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        if columns_to_include:
            df = df[columns_to_include]
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        missing_strategy = mapping_config.get('missingValues', 'zeros')
        if missing_strategy == 'remove':
            df = df.dropna()
        elif missing_strategy == 'zeros':
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            df[numeric_cols] = df[numeric_cols].fillna(0)
        elif missing_strategy == 'mean':
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
        if mapping_config.get('detectOutliers', False):
            threshold = mapping_config.get('outlierThreshold', 3)
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            
            for col in numeric_cols:
                z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())
                outliers = z_scores > threshold
                
                if mapping_config.get('removeOutliers', False):
                    df = df[~outliers]
                else:
                    # –ó–∞–º–µ–Ω—è–µ–º –≤—ã–±—Ä–æ—Å—ã –Ω–∞ –º–µ–¥–∏–∞–Ω—É
                    df.loc[outliers, col] = df[col].median()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        if mapping_config.get('normalizeData', False):
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        if mapping_config.get('logTransform', False):
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if (df[col] > 0).all():
                    df[col] = np.log1p(df[col])
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if mapping_config.get('createFeatures', False):
            time_series = mapping_config.get('timeSeries', {})
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
            if time_series.get('date'):
                date_col = df.columns[int(time_series['date'])]
                if date_col in df.columns:
                    df['date_parsed'] = pd.to_datetime(df[date_col], errors='coerce')
                    df['year'] = df['date_parsed'].dt.year
                    df['month'] = df['date_parsed'].dt.month
                    df['quarter'] = df['date_parsed'].dt.quarter
                    df['week'] = df['date_parsed'].dt.isocalendar().week
            
            if time_series.get('year'):
                year_col = df.columns[int(time_series['year'])]
                if year_col in df.columns:
                    df['year'] = pd.to_numeric(df[year_col], errors='coerce')
            
            if time_series.get('month'):
                month_col = df.columns[int(time_series['month'])]
                if month_col in df.columns:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–µ—Å—è—Ü–µ–≤
                    month_mapping = {
                    '—è–Ω–≤–∞—Ä—å': 1, '—Ñ–µ–≤—Ä–∞–ª—å': 2, '–º–∞—Ä—Ç': 3, '–∞–ø—Ä–µ–ª—å': 4,
                    '–º–∞–π': 5, '–∏—é–Ω—å': 6, '–∏—é–ª—å': 7, '–∞–≤–≥—É—Å—Ç': 8,
                    '—Å–µ–Ω—Ç—è–±—Ä—å': 9, '–æ–∫—Ç—è–±—Ä—å': 10, '–Ω–æ—è–±—Ä—å': 11, '–¥–µ–∫–∞–±—Ä—å': 12
                    }
                    if df[month_col].dtype == 'object':
                        df['month'] = df[month_col].str.lower().map(month_mapping).fillna(pd.to_numeric(df[month_col], errors='coerce'))
                else:
                    df['month'] = pd.to_numeric(df[month_col], errors='coerce')
            
            if time_series.get('quarter'):
                quarter_col = df.columns[int(time_series['quarter'])]
                if quarter_col in df.columns:
                    df['quarter'] = pd.to_numeric(df[quarter_col], errors='coerce')
            
            if time_series.get('week'):
                week_col = df.columns[int(time_series['week'])]
                if week_col in df.columns:
                    df['week'] = pd.to_numeric(df[week_col], errors='coerce')
            
            if time_series.get('halfyear'):
                halfyear_col = df.columns[int(time_series['halfyear'])]
                if halfyear_col in df.columns:
                    df['halfyear'] = pd.to_numeric(df[halfyear_col], errors='coerce')
            
            # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            if 'year' in df.columns and 'month' in df.columns:
                df['season'] = df['month'].map({12: 0, 1: 0, 2: 0,  # –ó–∏–º–∞
                                       3: 1, 4: 1, 5: 1,    # –í–µ—Å–Ω–∞
                                       6: 2, 7: 2, 8: 2,    # –õ–µ—Ç–æ
                                       9: 3, 10: 3, 11: 3}) # –û—Å–µ–Ω—å
                df['is_weekend'] = 0  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –±—É–¥—É—â–µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —ç–∫–∑–µ–º–ø–ª—è—Ä–µ
        self.df = df
        
        return df
    
    def set_data_mapping(self, mapping):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–æ–ª–æ–Ω–æ–∫"""
        self.data_mapping = mapping
        print(f"\nüó∫Ô∏è –ú–ê–ü–ü–ò–ù–ì –î–ê–ù–ù–´–•:")
        for key, value in mapping.items():
            print(f"  {key}: –∫–æ–ª–æ–Ω–∫–∞ {value}")
    
    def run_cascaded_forecast(self, config):
        """–ó–∞–ø—É—Å–∫ –∫–∞—Å–∫–∞–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å Random Forest"""
        try:
            print(f"\nüîÆ –ó–ê–ü–£–°–ö –ö–ê–°–ö–ê–î–ù–û–ì–û –ü–†–û–ì–ù–û–ó–ê:")
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            periods = config.get('periods', 4)
            method = config.get('method', 'random_forest')
            year_col = self.data_mapping.get('year', 0)
            month_col = self.data_mapping.get('month', 1)
            
            print(f"  –ü–µ—Ä–∏–æ–¥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞: {periods}")
            print(f"  –ú–µ—Ç–æ–¥: {method}")
            print(f"  –ö–æ–ª–æ–Ω–∫–∞ –≥–æ–¥–∞: {year_col}")
            print(f"  –ö–æ–ª–æ–Ω–∫–∞ –º–µ—Å—è—Ü–∞: {month_col}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if year_col >= len(self.df.columns) or month_col >= len(self.df.columns):
                return False, "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–∫–∞–∑–∞–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –≥–æ–¥–∞ –∏–ª–∏ –º–µ—Å—è—Ü–∞"
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            year_col_name = self.df.columns[year_col]
            month_col_name = self.df.columns[month_col]
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            self.df[year_col_name] = pd.to_numeric(self.df[year_col_name], errors='coerce')
            self.df[month_col_name] = pd.to_numeric(self.df[month_col_name], errors='coerce')
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            self.df = self.df.dropna(subset=[year_col_name, month_col_name])
            
            if len(self.df) < 10:
                return False, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
            
            # –ù–∞—Ö–æ–¥–∏–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
            numeric_cols = []
            for i, col in enumerate(self.df.columns):
                if i not in [year_col, month_col] and pd.api.types.is_numeric_dtype(self.df[col]):
                    if self.df[col].sum() > 0:  # –¢–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
                        numeric_cols.append(i)
            
            if not numeric_cols:
                return False, "–ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
            
            print(f"  –ù–∞–π–¥–µ–Ω–æ {len(numeric_cols)} —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–π —á–∏—Å–ª–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏
            forecast_data = []
            
            for col_idx in numeric_cols:
                col_name = self.df.columns[col_idx]
                print(f"\n  üìä –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è {col_name}:")
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                forecast_result = self._create_forecast_for_column(
                    col_name, year_col_name, month_col_name, periods, method
                )
                
                if forecast_result:
                    forecast_data.append(forecast_result)
                    print(f"    ‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ —Å–æ–∑–¥–∞–Ω")
                else:
                    print(f"    ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞")
            
            if not forecast_data:
                return False, "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞"
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.forecast_results = {
                'forecast_data': forecast_data,
                'settings': config,
                'total_forecasts': len(forecast_data)
            }
            
            return True, f"–°–æ–∑–¥–∞–Ω–æ {len(forecast_data)} –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"
            
        except Exception as e:
            return False, f"–û—à–∏–±–∫–∞ –≤ –∫–∞—Å–∫–∞–¥–Ω–æ–º –ø—Ä–æ–≥–Ω–æ–∑–µ: {str(e)}"
    
    def _create_forecast_for_column(self, col_name, year_col, month_col, periods, method):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏"""
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            data = self.df[[year_col, month_col, col_name]].copy()
            data = data.dropna()
            
            if len(data) < 6:
                return None
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å
            data['time_index'] = (data[year_col] - data[year_col].min()) * 12 + (data[month_col] - 1)
            
            # –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            data['month_sin'] = np.sin(2 * np.pi * data[month_col] / 12)
            data['month_cos'] = np.cos(2 * np.pi * data[month_col] / 12)
            
            # –ö–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            data['quarter'] = ((data[month_col] - 1) // 3) + 1
            for q in range(1, 5):
                data[f'q{q}'] = (data['quarter'] == q).astype(int)
            
            # –ü—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
            data['holiday_period'] = (
                (data[month_col] == 12) |  # –î–µ–∫–∞–±—Ä—å
                (data[month_col] == 1) |   # –Ø–Ω–≤–∞—Ä—å
                (data[month_col] == 2) |   # –§–µ–≤—Ä–∞–ª—å
                (data[month_col] == 3) |   # –ú–∞—Ä—Ç
                (data[month_col] == 5)     # –ú–∞–π
            ).astype(int)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = ['time_index', 'month_sin', 'month_cos', 'q1', 'q2', 'q3', 'q4', 'holiday_period']
            X = data[features].fillna(0)
            y = data[col_name].fillna(0)
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å
            if method == 'random_forest':
                model = RandomForestRegressor(n_estimators=100, random_state=42)
            else:
                model = Ridge(alpha=1.0)
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            model.fit(X, y)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            y_pred = model.predict(X)
            r2 = r2_score(y, y_pred)
            mae = mean_absolute_error(y, y_pred)
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
            last_year = data[year_col].max()
            last_month = data[month_col].max()
            last_time_index = data['time_index'].max()
            
            forecast_periods = []
            for i in range(1, periods + 1):
                period_data = {
                    'year': last_year + (i // 12),
                    'month': ((last_month + i - 1) % 12) + 1,
                    'time_index': last_time_index + i,
                    'month_sin': np.sin(2 * np.pi * (((last_month + i - 1) % 12) + 1) / 12),
                    'month_cos': np.cos(2 * np.pi * (((last_month + i - 1) % 12) + 1) / 12),
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                month = period_data['month']
                quarter = ((month - 1) // 3) + 1
                for q in range(1, 5):
                    period_data[f'q{q}'] = 1 if quarter == q else 0
                
                # –ü—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
                period_data['holiday_period'] = 1 if month in [12, 1, 2, 3, 5] else 0
                
                # –ü—Ä–æ–≥–Ω–æ–∑
                X_forecast = np.array([period_data[feature] for feature in features]).reshape(1, -1)
                forecast_value = model.predict(X_forecast)[0]
                forecast_value = max(0, forecast_value)  # –ù–µ –¥–æ–ø—É—Å–∫–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                
                period_data['forecast'] = forecast_value
                forecast_periods.append(period_data)
            
            return {
                'column_name': col_name,
                'model_type': method,
                'r2': r2,
                'mae': mae,
                'forecast_periods': forecast_periods,
                'total_forecast': sum(p['forecast'] for p in forecast_periods)
            }
            
        except Exception as e:
            print(f"    –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {col_name}: {str(e)}")
            return None
    
    def save_results(self, session_id):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            if not self.forecast_results:
                return None
            
            # –°–æ–∑–¥–∞–µ–º DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            all_results = []
            
            for forecast in self.forecast_results['forecast_data']:
                for period in forecast['forecast_periods']:
                    all_results.append({
                    'column': forecast['column_name'],
                    'year': period['year'],
                    'month': period['month'],
                    'forecast': period['forecast'],
                    'model_type': forecast['model_type'],
                    'r2': forecast['r2'],
                    'mae': forecast['mae']
                    })
            
            if all_results:
                results_df = pd.DataFrame(all_results)
                filename = f"cascaded_forecast_{session_id}.csv"
                filepath = os.path.join(app.config['RESULTS_FOLDER'], filename)
                results_df.to_csv(filepath, index=False, encoding='utf-8')
                print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
                return filepath
            
            return None
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {str(e)}")
            return None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
forecast_app = WorkingForecastApp()

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ - –¥–∞—à–±–æ—Ä–¥"""
    return render_template('dashboard.html', username='–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å', projects=[])

@app.route('/forecast')
def forecast():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
    project_id = request.args.get('project')
    if project_id:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ–µ–∫—Ç
        try:
            project_file = os.path.join('projects', f"{project_id}.json")
            if os.path.exists(project_file):
                with open(project_file, 'r', encoding='utf-8') as f:
                    project = json.load(f)
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ forecast_app
                if project.get('data_info'):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ data_info
                    if project['data_info'].get('full_data'):
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ data_info
                        full_data = project['data_info']['full_data']
                    df = pd.DataFrame(full_data)
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –∑–∞–º–µ–Ω—è–µ–º NaN
                    df = df.fillna('')
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π
                    df = df.replace([np.nan, 'nan', 'NaN'], '')
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ forecast_app
                    forecast_app.df = df
                    forecast_app.session_id = project['session_id']
                elif project.get('processed_data') and project['processed_data'].get('sample_data'):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ processed_data
                    sample_data = project['processed_data']['sample_data']
                    df = pd.DataFrame(sample_data)
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –∑–∞–º–µ–Ω—è–µ–º NaN
                    df = df.fillna('')
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π
                    df = df.replace([np.nan, 'nan', 'NaN'], '')
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ forecast_app
                    forecast_app.df = df
                    forecast_app.session_id = project['session_id']
                else:
                    # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º sample_data –∏–∑ data_info
                    sample_data = project['data_info'].get('sample_data', [])
                    if sample_data:
                        df = pd.DataFrame(sample_data)
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –∑–∞–º–µ–Ω—è–µ–º NaN
                    df = df.fillna('')
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ NaN –∑–Ω–∞—á–µ–Ω–∏–π
                    df = df.replace([np.nan, 'nan', 'NaN'], '')
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ forecast_app
                    forecast_app.df = df
                    forecast_app.session_id = project['session_id']
                    print(f"DEBUG: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –≤ forecast_app –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ {project_id}")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
                    project['updated_at'] = datetime.now().isoformat()
                    with open(project_file, 'w', encoding='utf-8') as f:
                        json.dump(project, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–æ–µ–∫—Ç–∞: {e}")
    
    return render_template('marfor_interface.html')

@app.route('/logout')
def logout():
    """–í—ã—Ö–æ–¥ –∏–∑ —Å–∏—Å—Ç–µ–º—ã"""
    return redirect('/')

@app.route('/favicon.ico')
def favicon():
    """Favicon"""
    return '', 204  # No Content

@app.route('/forecast/mapping')
def data_mapping():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö"""
    return render_template('data_mapping.html')

@app.route('/forecast/settings')
def forecast_settings():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
    return render_template('forecast_settings.html')

@app.route('/forecast/training')
def model_training():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π"""
    return render_template('model_training.html')

@app.route('/forecast/results')
def forecast_results():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    return render_template('forecast_results.html')

@app.route('/forecast/configure')
def forecast_configure():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    return render_template('marfor_interface.html')

@app.route('/demo/mapping')
def demo_mapping():
    """–î–µ–º–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –º–∞–ø–ø–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö"""
    return render_template('demo_mapping.html')

@app.route('/api/apply_mapping', methods=['POST'])
def apply_mapping():
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        mapping_config = data.get('mapping')
        
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
        processed_data = forecast_app.apply_data_mapping(mapping_config)
        
        return jsonify({
            'success': True,
            'message': '–ú–∞–ø–ø–∏–Ω–≥ –ø—Ä–∏–º–µ–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ',
            'processed_data_info': {
                'shape': processed_data.shape,
                'columns': list(processed_data.columns),
                'dtypes': {col: str(dtype) for col, dtype in processed_data.dtypes.items()},
                'missing_values': processed_data.isnull().sum().to_dict(),
                'sample_data': convert_to_json_serializable(processed_data.head(5).fillna('').to_dict('records'))
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –º–∞–ø–ø–∏–Ω–≥–∞: {str(e)}'})

@app.route('/api/get_processed_data/<session_id>')
def get_processed_data(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    try:
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        if forecast_app.df is None:
            return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        data_info = forecast_app.get_data_info()
        
        return jsonify({
            'success': True,
            'data_info': data_info
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}'})

@app.route('/api/get_time_series_data/<session_id>')
def get_time_series_data(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    try:
        print(f"üîß –í–ï–†–°–ò–Ø –ö–û–î–ê: 2.21.0 - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        use_forecast = request.args.get('use_forecast', 'false').lower() == 'true'
        
        if use_forecast:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ñ–∞–∫—Ç + –ø—Ä–æ–≥–Ω–æ–∑)
            if not hasattr(forecast_app, 'forecast_results') or session_id not in forecast_app.forecast_results:
                return jsonify({'success': False, 'message': '–ü—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
            
            combined_data = forecast_app.forecast_results[session_id]['combined_data']
            df = pd.DataFrame(combined_data)
            print(f"DEBUG: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(df)} —Å—Ç—Ä–æ–∫ (—Ñ–∞–∫—Ç + –ø—Ä–æ–≥–Ω–æ–∑)")
            print(f"DEBUG: –ö–æ–ª–æ–Ω–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {list(df.columns)}")
            if 'is_forecast' in df.columns:
                forecast_count = df['is_forecast'].sum()
                print(f"DEBUG: –ü—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {forecast_count}, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö: {len(df) - forecast_count}")
            else:
                print(f"WARNING: –ö–æ–ª–æ–Ω–∫–∞ 'is_forecast' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö!")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if forecast_app.df is None:
                return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
            
            df = forecast_app.df.copy()
            print(f"DEBUG: –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {len(df)} —Å—Ç—Ä–æ–∫")
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"DEBUG: –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")
        print(f"DEBUG: –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        time_column = request.args.get('time_column', '')
        metric_columns = request.args.getlist('metrics')
        slice_columns = request.args.getlist('slices')  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É —Å—Ä–µ–∑–æ–≤
        group_by = request.args.get('group_by', '')
        show_pivot = request.args.get('show_pivot', 'false').lower() == 'true'
        pivot_mode = request.args.get('pivot_mode', 'time-series')  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
        split_by_slice = request.args.get('split_by_slice', '')  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ —Å—Ä–µ–∑–∞–º
        
        print(f"DEBUG: time_column={time_column}, metrics={metric_columns}, group_by={group_by}, show_pivot={show_pivot}, pivot_mode={pivot_mode}, split_by_slice={split_by_slice}")
        print(f"DEBUG: –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞: {dict(request.args)}")
        
        # –ü–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
        mapping_data = request.args.get('mapping_data', '{}')
        import json
        try:
            mapping_config = json.loads(mapping_data) if mapping_data else {}
        except json.JSONDecodeError as e:
            print(f"ERROR: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON –≤ –º–∞–ø–ø–∏–Ω–≥–µ: {e}")
            return jsonify({
                'success': False, 
                'message': f'–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –º–∞–ø–ø–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö. –û—à–∏–±–∫–∞ JSON: {str(e)}'
            })
        
        print(f"DEBUG: –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {mapping_config}")
        print(f"DEBUG: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫ –≤ –º–∞–ø–ø–∏–Ω–≥–µ: {len(mapping_config.get('columns', []))}")
        
        if not mapping_config or not mapping_config.get('columns'):
            print("ERROR: –ú–∞–ø–ø–∏–Ω–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç–æ–π - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞!")
            return jsonify({
                'success': False, 
                'message': '–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –º–∞–ø–ø–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏–ª–∏ –ø—É—Å—Ç–æ–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã.'
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞
        if pivot_mode == 'time-series':
            if not time_column or not metric_columns:
                return jsonify({'success': False, 'message': '–ù–µ —É–∫–∞–∑–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –∏–ª–∏ –º–µ—Ç—Ä–∏–∫–∏'})
        else:  # pivot_mode == 'slices'
            if not time_column or not slice_columns:
                return jsonify({'success': False, 'message': '–ù–µ —É–∫–∞–∑–∞–Ω—ã –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –∏–ª–∏ —Å—Ä–µ–∑—ã'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        if time_column not in df.columns:
            return jsonify({'success': False, 'message': f'–í—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ {time_column} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        for metric in metric_columns:
            if metric not in df.columns:
                return jsonify({'success': False, 'message': f'–ú–µ—Ç—Ä–∏–∫–∞ {metric} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        result_data = {
            'time_series': [],
            'grouped_series': {},
            'time_labels': [],
            'metrics': metric_columns,
            'pivot_table': None
        }
        
        print(f"DEBUG: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–ª–æ–Ω–∫–∏: {df.columns.tolist()}")
        print(f"DEBUG: –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        for i, row in enumerate(df.head(3).to_dict('records')):
            print(f"  –°—Ç—Ä–æ–∫–∞ {i}: {row}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        df_sorted = df.sort_values(time_column)
        
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        time_labels = df_sorted[time_column].unique()
        result_data['time_labels'] = [str(label) for label in time_labels]
        
        print(f"DEBUG: –ù–∞–π–¥–µ–Ω–æ {len(time_labels)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫: {time_labels[:10]}...")
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
        if group_by and group_by in df.columns:
            groups = df_sorted[group_by].unique()
            
            for group in groups:
                group_data = df_sorted[df_sorted[group_by] == group]
                group_series = {}
                
                for metric in metric_columns:
                    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å—É–º–º–∞ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö, –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö)
                    if df[metric].dtype in ['int64', 'float64']:
                        metric_data = group_data.groupby(time_column)[metric].sum()
                else:
                    metric_data = group_data.groupby(time_column)[metric].last()
                    
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
                    full_series = []
                    for time_label in time_labels:
                        if time_label in metric_data.index:
                            full_series.append(float(metric_data[time_label]) if pd.notna(metric_data[time_label]) else 0)
                        else:
                            full_series.append(0)
                    
                    group_series[metric] = full_series
                
                result_data['grouped_series'][str(group)] = group_series
        else:
            # –ë–µ–∑ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ - –æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            for metric in metric_columns:
                if df[metric].dtype in ['int64', 'float64']:
                    metric_data = df_sorted.groupby(time_column)[metric].sum()
                else:
                    metric_data = df_sorted.groupby(time_column)[metric].last()
                
                # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
                full_series = []
                for time_label in time_labels:
                    if time_label in metric_data.index:
                        full_series.append(float(metric_data[time_label]) if pd.notna(metric_data[time_label]) else 0)
                    else:
                        full_series.append(0)
                
                result_data['time_series'].append({
                    'metric': metric,
                    'data': full_series
                })
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ
        print(f"DEBUG: show_pivot = {show_pivot}")
        if show_pivot:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–∑ sessionStorage (–ø–µ—Ä–µ–¥–∞–µ–º —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
                mapping_data = request.args.get('mapping_data', '{}')
                import json
                mapping = json.loads(mapping_data) if mapping_data else {}
                
                print(f"DEBUG: –ü–æ–ª—É—á–µ–Ω –º–∞–ø–ø–∏–Ω–≥: {mapping}")
                
                # –ù–∞—Ö–æ–¥–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å —É—Ä–æ–≤–Ω—è–º–∏
                time_series_cols = []
                slice_cols = []
                if mapping.get('columns'):
                    for col in mapping['columns']:
                        if col.get('time_series') and col.get('nesting_level', 0) >= 0:
                            time_series_cols.append({
                                'name': col['name'],
                                'type': col['time_series'],
                                'level': col['nesting_level']
                            })
                        elif col.get('role') == 'dimension' and not col.get('time_series') and col.get('nesting_level', 0) >= 0:
                            slice_cols.append({
                                'name': col['name'],
                                'type': 'slice',
                                'level': col['nesting_level']
                            })
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É—Ä–æ–≤–Ω—è–º
                time_series_cols.sort(key=lambda x: x['level'])
                slice_cols.sort(key=lambda x: x['level'])
                
                print(f"DEBUG: –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã: {time_series_cols}")
                print(f"DEBUG: –°—Ä–µ–∑—ã: {slice_cols}")
                
                # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∂–∏–º–∞ —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                print(f"DEBUG: pivot_mode = {pivot_mode}")
                print(f"DEBUG: split_by_slice = {split_by_slice}")
                
                if pivot_mode == 'time-series' and time_series_cols:
                    # –í —Ä–µ–∂–∏–º–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                    print(f"DEBUG: –ü–æ–ø–∞–¥–∞–µ–º –≤ –±–ª–æ–∫ time-series")
                    time_cols = time_series_cols.copy()
                    
                    if split_by_slice and split_by_slice in [col['name'] for col in slice_cols]:
                        print(f"DEBUG: –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ —Å—Ä–µ–∑—É: {split_by_slice}")
                        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Å—Ä–µ–∑—É - –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∞—Ö, —Å—Ä–µ–∑ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö
                        split_col = [col for col in slice_cols if col['name'] == split_by_slice][0]
                        print(f"DEBUG: –ù–∞–π–¥–µ–Ω —Å—Ä–µ–∑ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏: {split_col}")
                        
                        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —Å—Ä–µ–∑—É
                        pivot_cols = [col['name'] for col in time_cols]
                        print(f"DEBUG: –†–∞–∑–±–∏–≤–∫–∞ –ø–æ —Å—Ä–µ–∑—É {split_by_slice}, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {pivot_cols}")
                    else:
                        print(f"DEBUG: –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –±–µ–∑ —Ä–∞–∑–±–∏–≤–∫–∏")
                        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ - —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                        pivot_cols = [col['name'] for col in time_cols]
                        print(f"DEBUG: –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {pivot_cols}")
                    
                    # –°–æ–∑–¥–∞–µ–º pivot table —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
                    if split_by_slice and split_by_slice in [col['name'] for col in slice_cols]:
                        # –° —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —Å—Ä–µ–∑—É
                        pivot_data = df_sorted.groupby(pivot_cols + [split_by_slice])[metric_columns].sum().reset_index()
                    else:
                        # –ë–µ–∑ —Ä–∞–∑–±–∏–≤–∫–∏ - —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                        pivot_data = df_sorted.groupby(pivot_cols)[metric_columns].sum().reset_index()
                    
                    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º
                    if split_by_slice and split_by_slice in [col['name'] for col in slice_cols]:
                        unique_slices = sorted(pivot_data[split_by_slice].unique())
                        column_headers = {}
                        
                        for slice_value in unique_slices:
                            slice_data = pivot_data[pivot_data[split_by_slice] == slice_value]
                            column_headers[str(slice_value)] = {}
                            for metric in metric_columns:
                                column_headers[str(slice_value)][metric] = {}
                                for _, row in slice_data.iterrows():
                                    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                                    time_key = '_'.join(str(row[col]) for col in pivot_cols)
                                    column_headers[str(slice_value)][metric][time_key] = float(row[metric]) if pd.notna(row[metric]) else 0
                    else:
                        # –ë–µ–∑ —Ä–∞–∑–±–∏–≤–∫–∏ - –ø—Ä–æ—Å—Ç—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏
                        unique_slices = []
                        column_headers = {}
                    
                    # –í–∫–ª—é—á–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ —Å—Ä–µ–∑–∞–º
                    all_mapping_columns = [col['name'] for col in mapping_config.get('columns', [])]
                    available_columns = [col for col in all_mapping_columns if col in df_sorted.columns]
                    
                    if split_by_slice and split_by_slice in [col['name'] for col in slice_cols]:
                        result_data['pivot_table'] = {
                            'columns': available_columns,
                            'data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),
                            'raw_data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
                            'time_series_info': time_cols + [split_col],
                            'column_headers': convert_to_json_serializable(column_headers),
                            'split_by_slice': split_by_slice,
                            'unique_slices': convert_to_json_serializable(unique_slices),
                            'metrics': metric_columns,
                            'available_slices': slice_cols,
                            'pivot_mode': 'time-series'  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                        }
                    else:
                        result_data['pivot_table'] = {
                            'columns': available_columns,
                            'data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),
                            'raw_data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
                            'time_series_info': time_cols,
                            'column_headers': convert_to_json_serializable(column_headers),
                            'split_by_slice': '',
                            'unique_slices': convert_to_json_serializable(unique_slices),
                            'metrics': metric_columns,
                            'available_slices': slice_cols,
                            'pivot_mode': 'time-series'  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                        }
                    
                    print(f"DEBUG: –°–æ–∑–¥–∞–Ω–∞ —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π:")
                    print(f"  - –ö–æ–ª–æ–Ω–∫–∏: {pivot_cols}")
                    print(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ä–µ–∑—ã: {unique_slices}")
                    print(f"  - –ú–µ—Ç—Ä–∏–∫–∏: {metric_columns}")
                    print(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö: {len(pivot_data)}")
                    print(f"  - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ column_headers: {list(column_headers.keys())}")
                    print(f"  - –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
                    for i, row in enumerate(pivot_data.head(3).to_dict('records')):
                        print(f"    –°—Ç—Ä–æ–∫–∞ {i}: {row}")
                    print(f"  - –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {pivot_data.columns.tolist()}")
                    print(f"  - –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {pivot_data.dtypes.to_dict()}")
                    
                    print(f"DEBUG: –°–æ–∑–¥–∞–Ω–∞ —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ {split_by_slice}, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {unique_slices}")
                else:
                    # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ - —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                    all_cols = time_series_cols.copy()
                    print(f"DEBUG: –†–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {all_cols}")
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                    pivot_cols = [col['name'] for col in all_cols]
                    print(f"DEBUG: –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã: {pivot_cols}")
                    print(f"DEBUG: –ú–µ—Ç—Ä–∏–∫–∏: {metric_columns}")
                    
                    pivot_data = df_sorted.groupby(pivot_cols)[metric_columns].sum().reset_index()
                    print(f"DEBUG: –°–æ–∑–¥–∞–Ω–∞ —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å {len(pivot_data)} —Å—Ç—Ä–æ–∫–∞–º–∏")
                    
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    # –í–∫–ª—é—á–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
                    all_mapping_columns = [col['name'] for col in mapping_config.get('columns', [])]
                    available_columns = [col for col in all_mapping_columns if col in df_sorted.columns]
                    
                    result_data['pivot_table'] = {
                        'columns': available_columns,
                        'data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),
                        'raw_data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
                        'time_series_info': all_cols,
                        'available_slices': slice_cols,
                        'pivot_mode': 'time-series'  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
                    }
                
                if pivot_mode == 'slices':
                    # –í —Ä–µ–∂–∏–º–µ —Å—Ä–µ–∑–æ–≤ - —Å—Ä–µ–∑—ã –≤ —Å—Ç—Ä–æ–∫–∞—Ö, –º–µ—Ç—Ä–∏–∫–∏/–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö
                    print(f"DEBUG: –ü–æ–ø–∞–¥–∞–µ–º –≤ –±–ª–æ–∫ slices")
                    if split_by_slice and split_by_slice in [col['name'] for col in time_series_cols]:
                        print(f"DEBUG: –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ä—è–¥—É: {split_by_slice}")
                        # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ä—è–¥—É - —Å—Ä–µ–∑—ã –≤ —Å—Ç—Ä–æ–∫–∞—Ö, –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö
                        slice_col_names = [col['name'] for col in slice_cols]
                        split_col = [col for col in time_series_cols if col['name'] == split_by_slice][0]
                        print(f"DEBUG: –ù–∞–π–¥–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏: {split_col}")
                    
                        # –°–æ–∑–¥–∞–µ–º pivot table —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
                        pivot_data = df_sorted.groupby(slice_col_names + [split_by_slice])[metric_columns].sum().reset_index()
                        
                        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º (–∫–∞–∫ –≤ —Ä–µ–∂–∏–º–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
                        unique_time_values = sorted(pivot_data[split_by_slice].unique())
                        column_headers = {}
                        
                        for time_value in unique_time_values:
                            time_data = pivot_data[pivot_data[split_by_slice] == time_value]
                            column_headers[str(time_value)] = {}
                            for metric in metric_columns:
                                column_headers[str(time_value)][metric] = {}
                                for _, row in time_data.iterrows():
                                    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∏–∑ —Å—Ä–µ–∑–æ–≤ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–∞–º)
                                    slice_key = '_'.join(str(row[col]) for col in slice_col_names)
                                    column_headers[str(time_value)][metric][slice_key] = float(row[metric]) if pd.notna(row[metric]) else 0
                        
                        # –í–∫–ª—é—á–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞ –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ä—è–¥—É
                        all_mapping_columns = [col['name'] for col in mapping_config.get('columns', [])]
                        available_columns = [col for col in all_mapping_columns if col in df_sorted.columns]
                        
                        result_data['pivot_table'] = {
                            'columns': available_columns,
                            'data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),
                            'raw_data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
                            'time_series_info': [],  # –í —Ä–µ–∂–∏–º–µ —Å—Ä–µ–∑–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –ù–ï –≤ —Å—Ç—Ä–æ–∫–∞—Ö
                            'column_headers': convert_to_json_serializable(column_headers),
                            'split_by_slice': split_by_slice,
                            'unique_time_values': convert_to_json_serializable(unique_time_values),
                            'metrics': metric_columns,
                            'available_slices': slice_cols,  # –°—Ä–µ–∑—ã –¥–ª—è —Å—Ç—Ä–æ–∫
                            'available_time_series': time_series_cols,  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º
                            'pivot_mode': 'slices'  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º —Å—Ä–µ–∑–æ–≤
                        }
                    else:
                        # –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º —Å—Ä–µ–∑–æ–≤ –±–µ–∑ —Ä–∞–∑–±–∏–≤–∫–∏
                        print(f"DEBUG: –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º —Å—Ä–µ–∑–æ–≤")
                        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å —Å—Ä–µ–∑–∞–º–∏ –≤ —Å—Ç—Ä–æ–∫–∞—Ö, –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤ –∑–Ω–∞—á–µ–Ω–∏—è—Ö
                        print(f"DEBUG: –í—Å–µ —Å—Ä–µ–∑—ã: {slice_cols}")
                        print(f"DEBUG: –ú–µ—Ç—Ä–∏–∫–∏: {metric_columns}")
                        
                        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                        # –í–∫–ª—é—á–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
                        all_mapping_columns = [col['name'] for col in mapping_config.get('columns', [])]
                        available_columns = [col for col in all_mapping_columns if col in df_sorted.columns]
                        
                        result_data['pivot_table'] = {
                            'columns': available_columns,
                            'data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),
                            'raw_data': convert_to_json_serializable(df_sorted[available_columns].to_dict('records')),  # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–æ–≤
                            'time_series_info': [],  # –í —Ä–µ–∂–∏–º–µ —Å—Ä–µ–∑–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –Ω–µ –≤ —Å—Ç—Ä–æ–∫–∞—Ö
                            'available_slices': slice_cols,  # –°—Ä–µ–∑—ã –¥–ª—è —Å—Ç—Ä–æ–∫
                            'available_time_series': time_series_cols,  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏
                            'metrics': metric_columns,  # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏–π
                            'pivot_mode': 'slices'  # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º —Å—Ä–µ–∑–æ–≤
                        }
                        
                        print(f"DEBUG: –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞ –≤ —Ä–µ–∂–∏–º–µ 'slices'")
                    
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤–æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã: {e}")
                result_data['pivot_table'] = None
        
        return jsonify({
            'success': True,
            'data': result_data
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤: {str(e)}'})

@app.route('/api/save_project', methods=['POST'])
def save_project():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        data = request.get_json()
        project_name = data.get('name', '')
        session_id = data.get('session_id', '')
        
        if not project_name:
            return jsonify({'success': False, 'message': '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'})
        
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –ø—Ä–æ–µ–∫—Ç–∞
        data_info = forecast_app.get_data_info()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ data_info
        if forecast_app.df is not None:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ sample
            # –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ None –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            df_clean = forecast_app.df.fillna('')
            data_info['full_data'] = convert_to_json_serializable(df_clean.to_dict('records'))
        
        project = {
            'id': str(uuid.uuid4()),
            'name': project_name,
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat(),
            'session_id': session_id,
            'data_info': data_info,
            'data_mapping': data.get('data_mapping', {}),
            'processed_data': data.get('processed_data', {}),
            'status': 'saved'
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        projects_dir = 'projects'
        os.makedirs(projects_dir, exist_ok=True)
        
        project_file = os.path.join(projects_dir, f"{project['id']}.json")
        with open(project_file, 'w', encoding='utf-8') as f:
            json.dump(project, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'message': '–ü—Ä–æ–µ–∫—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ',
            'project_id': project['id']
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞: {str(e)}'})

@app.route('/api/load_project/<project_id>')
def load_project(project_id):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        project_file = os.path.join('projects', f"{project_id}.json")
        
        if not os.path.exists(project_file):
            return jsonify({'success': False, 'message': '–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'})
        
        with open(project_file, 'r', encoding='utf-8') as f:
            project = json.load(f)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞ –≤–º–µ—Å—Ç–æ JSON
        session_id = project.get('session_id')
        csv_loaded = False
        
        if session_id:
            # –ò—â–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –≤ uploads
            upload_folder = app.config['UPLOAD_FOLDER']
            matching_files = [f for f in os.listdir(upload_folder) if f.startswith(session_id)]
            
            if matching_files:
                original_file = os.path.join(upload_folder, matching_files[0])
                success, message = forecast_app.load_data_from_file(original_file)
                
                if success:
                    forecast_app.session_id = session_id
                    csv_loaded = True
                    print(f"‚úÖ –ü—Ä–æ–µ–∫—Ç {project.get('name')}: –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ CSV ({message})")
                else:
                    print(f"‚ö†Ô∏è –ü—Ä–æ–µ–∫—Ç {project.get('name')}: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV ({message})")
        
        # –ï—Å–ª–∏ CSV –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON (fallback)
        if not csv_loaded:
            print(f"‚ö†Ô∏è –ü—Ä–æ–µ–∫—Ç {project.get('name')}: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON (–≤–æ–∑–º–æ–∂–Ω–∞ –ø–æ—Ç–µ—Ä—è —Å—Ç—Ä–æ–∫)")
            # –ó–∞–≥—Ä—É–∂–∞–µ–º full_data –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
            full_data = project.get('data_info', {}).get('full_data', [])
            if full_data:
                forecast_app.df = pd.DataFrame(full_data)
                forecast_app.session_id = session_id or project_id
        
        # –û—á–∏—â–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–∞
        def clean_nan_values(obj):
            if isinstance(obj, dict):
                return {k: clean_nan_values(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [clean_nan_values(item) for item in obj]
            elif isinstance(obj, str) and obj in ['nan', 'NaN', 'null']:
                return ''
            elif pd.isna(obj) if hasattr(pd, 'isna') else False:
                return ''
            else:
                return obj
        
        # –û—á–∏—â–∞–µ–º —Ç–æ–ª—å–∫–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –Ω–æ –Ω–µ full_data (–æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–∏–º)
        project_clean = {
            'id': project.get('id'),
            'name': project.get('name'),
            'created_at': project.get('created_at'),
            'updated_at': datetime.now().isoformat(),
            'session_id': project.get('session_id'),
            'mapping_config': clean_nan_values(project.get('mapping_config', {})),
            'csv_loaded': csv_loaded
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        project['updated_at'] = datetime.now().isoformat()
        with open(project_file, 'w', encoding='utf-8') as f:
            json.dump(project, f, ensure_ascii=False, indent=2)
        
        return jsonify({
            'success': True,
            'project': project_clean
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø—Ä–æ–µ–∫—Ç–∞: {str(e)}'})

@app.route('/api/list_projects')
def list_projects():
    """–°–ø–∏—Å–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤"""
    try:
        projects_dir = 'projects'
        print(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–æ–≤: {projects_dir}")
        if not os.path.exists(projects_dir):
            print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {projects_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return jsonify({'success': True, 'projects': []})
        
        projects = []
        files = os.listdir(projects_dir)
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ {projects_dir}: {len(files)}")
        
        for filename in files:
            print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {filename}")
            if filename.endswith('.json'):
                project_file = os.path.join(projects_dir, filename)
                try:
                    with open(project_file, 'r', encoding='utf-8') as f:
                        project = json.load(f)
                    
                    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (–±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö)
                    if 'id' not in project:
                        # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∫–∞–∫ ID
                        project_id = filename.replace('.json', '')
                        project_name = project.get('data_info', {}).get('filename', '–ü—Ä–æ–µ–∫—Ç –±–µ–∑ –∏–º–µ–Ω–∏')
                        # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞
                        from time import strftime, localtime
                        mtime = os.path.getmtime(project_file)
                        timestamp = strftime('%Y-%m-%d %H:%M:%S', localtime(mtime))
                        
                        projects.append({
                            'id': project_id,
                            'name': project_name,
                            'created_at': timestamp,
                            'updated_at': timestamp,
                            'status': 'saved'
                        })
                        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω —Å—Ç–∞—Ä—ã–π –ø—Ä–æ–µ–∫—Ç: {project_name}")
                    else:
                        # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                        projects.append({
                            'id': project['id'],
                            'name': project['name'],
                            'created_at': project['created_at'],
                            'updated_at': project['updated_at'],
                            'status': project.get('status', 'saved')
                        })
                        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–µ–∫—Ç: {project.get('name', '–±–µ–∑ –∏–º–µ–Ω–∏')}")
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞ {filename}: {str(e)}")
                    continue
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        projects.sort(key=lambda x: x['updated_at'], reverse=True)
        
        return jsonify({
            'success': True,
            'projects': projects
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤: {str(e)}'})

@app.route('/api/delete_project/<project_id>', methods=['DELETE'])
def delete_project(project_id):
    """–£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        project_file = os.path.join('projects', f"{project_id}.json")
        
        if not os.path.exists(project_file):
            return jsonify({'success': False, 'message': '–ü—Ä–æ–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω'})
        
        os.remove(project_file)
        
        return jsonify({
            'success': True,
            'message': '–ü—Ä–æ–µ–∫—Ç —É–¥–∞–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ'
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞: {str(e)}'})

@app.route('/old')
def old_interface():
    """–°—Ç–∞—Ä—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å"""
    return render_template_string("""
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üìä –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #4285f4 0%, #34a853 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .main-content {
            padding: 40px;
        }

        .upload-section {
            background: #f8f9fa;
            border: 2px dashed #dee2e6;
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            margin-bottom: 30px;
            transition: all 0.3s ease;
        }

        .upload-section:hover {
            border-color: #4285f4;
            background: #f0f7ff;
        }

        .upload-section.dragover {
            border-color: #4285f4;
            background: #e3f2fd;
        }

        .file-input {
            display: none;
        }

        .upload-btn {
            background: #4285f4;
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 8px;
            font-size: 1.1em;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .upload-btn:hover {
            background: #3367d6;
            transform: translateY(-2px);
        }

        .settings-section {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }

        .setting-group {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            border-left: 4px solid #4285f4;
        }

        .setting-group h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 1.2em;
        }

        .form-group {
            margin-bottom: 15px;
        }

        .form-group label {
            display: block;
            margin-bottom: 5px;
            font-weight: 600;
            color: #555;
        }

        .form-group input,
        .form-group select {
            width: 100%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 1em;
        }

        .form-group input:focus,
        .form-group select:focus {
            outline: none;
            border-color: #4285f4;
            box-shadow: 0 0 0 2px rgba(66, 133, 244, 0.2);
        }

        .forecast-btn {
            background: linear-gradient(135deg, #34a853 0%, #137333 100%);
            color: white;
            border: none;
            padding: 15px 40px;
            border-radius: 8px;
            font-size: 1.2em;
            cursor: pointer;
            transition: all 0.3s ease;
            width: 100%;
            margin-bottom: 20px;
        }

        .forecast-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(52, 168, 83, 0.3);
        }

        .forecast-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .results-section {
            margin-top: 30px;
            display: none;
        }

        .results-section.show {
            display: block;
        }

        .results-header {
            background: #e8f5e8;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .results-header h3 {
            color: #137333;
            margin-bottom: 10px;
        }

        .download-btn {
            background: #ff6b35;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            margin-right: 10px;
            transition: all 0.3s ease;
        }

        .download-btn:hover {
            background: #e55a2b;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }

        .stat-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 10px;
            text-align: center;
            border-left: 4px solid #4285f4;
        }

        .stat-card h4 {
            color: #666;
            margin-bottom: 10px;
            font-size: 0.9em;
            text-transform: uppercase;
        }

        .stat-card .value {
            font-size: 2em;
            font-weight: bold;
            color: #333;
        }

        .loading {
            display: none;
            text-align: center;
            padding: 20px;
        }

        .loading.show {
            display: block;
        }

        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #4285f4;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 10px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .error {
            background: #f8d7da;
            color: #721c24;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
            border-left: 4px solid #dc3545;
        }

        .success {
            background: #d4edda;
            color: #155724;
            padding: 15px;
            border-radius: 5px;
            margin-bottom: 20px;
            border-left: 4px solid #28a745;
        }

        .data-info {
            background: #e3f2fd;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .data-info h4 {
            color: #1976d2;
            margin-bottom: 10px;
        }

        .column-mapping {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }

        .mapping-group {
            background: #fff3e0;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #ff9800;
        }

        .mapping-group h5 {
            color: #e65100;
            margin-bottom: 10px;
        }

        @media (max-width: 768px) {
            .main-content {
                padding: 20px;
            }
            
            .settings-section {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üìä –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö</h1>
            <p>–°–æ–∑–¥–∞–≤–∞–π—Ç–µ —Ç–æ—á–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–º–æ—â—å—é –∫–∞—Å–∫–∞–¥–Ω–æ–π –º–æ–¥–µ–ª–∏</p>
        </div>

        <div class="main-content">
            <!-- –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ -->
            <div class="upload-section" id="uploadSection">
                <h3>üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏</h3>
                <p>–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Ñ–∞–π–ª —Å—é–¥–∞ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –¥–ª—è –≤—ã–±–æ—Ä–∞</p>
                <input type="file" id="fileInput" class="file-input" accept=".csv,.xlsx,.xls" />
                <button class="upload-btn" onclick="document.getElementById('fileInput').click()">
                    –í—ã–±—Ä–∞—Ç—å —Ñ–∞–π–ª
                </button>
                <p style="margin-top: 15px; color: #666; font-size: 0.9em;">
                    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ñ–∞–π–ª—ã CSV, Excel —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: –≥–æ–¥, –º–µ—Å—è—Ü, —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                </p>
            </div>

            <!-- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö -->
            <div class="data-info" id="dataInfo" style="display: none;">
                <h4>üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö</h4>
                <div id="dataInfoContent"></div>
            </div>

            <!-- –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫ -->
            <div class="column-mapping" id="columnMapping" style="display: none;">
                <div class="mapping-group">
                    <h5>üóìÔ∏è –ö–æ–ª–æ–Ω–∫–∞ —Å –≥–æ–¥–æ–º</h5>
                    <select id="yearColumn" onchange="updateMapping()">
                    <option value="0">A (1-—è –∫–æ–ª–æ–Ω–∫–∞)</option>
                    </select>
                </div>
                <div class="mapping-group">
                    <h5>üìÖ –ö–æ–ª–æ–Ω–∫–∞ —Å –º–µ—Å—è—Ü–µ–º</h5>
                    <select id="monthColumn" onchange="updateMapping()">
                    <option value="1">B (2-—è –∫–æ–ª–æ–Ω–∫–∞)</option>
                    </select>
                </div>
            </div>

            <!-- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ -->
            <div class="settings-section">
                <div class="setting-group">
                    <h3>‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∞</h3>
                    <div class="form-group">
                    <label for="periods">–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞:</label>
                    <input type="number" id="periods" value="4" min="1" max="12" />
                    </div>
                    <div class="form-group">
                    <label for="method">–ú–µ—Ç–æ–¥ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:</label>
                    <select id="method">
                    <option value="random_forest">Random Forest (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)</option>
                    <option value="linear">–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è</option>
                    </select>
                    </div>
                </div>
            </div>

            <!-- –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ -->
            <button class="forecast-btn" id="forecastBtn" onclick="createForecast()" disabled>
                üîÆ –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑
            </button>

            <!-- –ó–∞–≥—Ä—É–∑–∫–∞ -->
            <div class="loading" id="loading">
                <div class="spinner"></div>
                <p>–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞...</p>
            </div>

            <!-- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã -->
            <div class="results-section" id="resultsSection">
                <div class="results-header">
                    <h3>‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!</h3>
                    <p>–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞</p>
                    <button class="download-btn" onclick="downloadResults()">üì• –°–∫–∞—á–∞—Ç—å CSV</button>
                </div>

                <div class="stats-grid" id="statsGrid">
                    <!-- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ -->
                </div>
            </div>
        </div>
    </div>

    <script>
        let sessionId = null;
        let dataInfo = null;

        // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞
        document.getElementById('fileInput').addEventListener('change', handleFileUpload);
        
        // Drag and drop
        const uploadSection = document.getElementById('uploadSection');
        uploadSection.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadSection.classList.add('dragover');
        });
        
        uploadSection.addEventListener('dragleave', () => {
            uploadSection.classList.remove('dragover');
        });
        
        uploadSection.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadSection.classList.remove('dragover');
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                handleFile(files[0]);
            }
        });

        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                handleFile(file);
            }
        }

        function handleFile(file) {
            if (!file.name.toLowerCase().match(/\\.(csv|xlsx|xls)$/)) {
                showError('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª');
                return;
            }

            const formData = new FormData();
            formData.append('file', file);

            showLoading(true);

            fetch('/upload', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                showLoading(false);
                if (data.success) {
                    sessionId = data.session_id;
                    dataInfo = data.data_info;
                    showDataInfo(dataInfo);
                    showSuccess(data.message);
                    document.getElementById('forecastBtn').disabled = false;
                } else {
                    showError(data.message);
                }
            })
            .catch(error => {
                showLoading(false);
                showError('–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: ' + error.message);
            });
        }

        function showDataInfo(info) {
            const dataInfoDiv = document.getElementById('dataInfo');
            const contentDiv = document.getElementById('dataInfoContent');
            
            let html = `
                <p><strong>–†–∞–∑–º–µ—Ä:</strong> ${info.shape[0]} —Å—Ç—Ä–æ–∫, ${info.shape[1]} –∫–æ–ª–æ–Ω–æ–∫</p>
                <p><strong>–ö–æ–ª–æ–Ω–∫–∏:</strong></p>
                <ul>
            `;
            
            info.columns.forEach((col, index) => {
                html += `<li>${index}: ${col} (${info.dtypes[col]})</li>`;
            });
            
            html += '</ul>';
            contentDiv.innerHTML = html;
            dataInfoDiv.style.display = 'block';
            
            // –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ–ª–µ–∫—Ç—ã –¥–ª—è –º–∞–ø–ø–∏–Ω–≥–∞
            updateColumnSelects();
        }

        function updateColumnSelects() {
            const yearSelect = document.getElementById('yearColumn');
            const monthSelect = document.getElementById('monthColumn');
            
            // –û—á–∏—â–∞–µ–º —Å–µ–ª–µ–∫—Ç—ã
            yearSelect.innerHTML = '';
            monthSelect.innerHTML = '';
            
            // –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏–∏
            dataInfo.columns.forEach((col, index) => {
                const option1 = document.createElement('option');
                option1.value = index;
                option1.textContent = `${String.fromCharCode(65 + index)} (${index + 1}-—è –∫–æ–ª–æ–Ω–∫–∞): ${col}`;
                yearSelect.appendChild(option1);
                
                const option2 = document.createElement('option');
                option2.value = index;
                option2.textContent = `${String.fromCharCode(65 + index)} (${index + 1}-—è –∫–æ–ª–æ–Ω–∫–∞): ${col}`;
                monthSelect.appendChild(option2);
            });
            
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            yearSelect.value = '0';
            monthSelect.value = '1';
            
            document.getElementById('columnMapping').style.display = 'grid';
        }

        function updateMapping() {
            // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–∞–ø–ø–∏–Ω–≥–∞ (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        }

        function createForecast() {
            if (!sessionId) {
                showError('–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏');
                return;
            }

            const settings = {
                periods: parseInt(document.getElementById('periods').value),
                method: document.getElementById('method').value,
                year_column: parseInt(document.getElementById('yearColumn').value),
                month_column: parseInt(document.getElementById('monthColumn').value)
            };

            showLoading(true);

            fetch('/forecast', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(settings)
            })
            .then(response => response.json())
            .then(data => {
                showLoading(false);
                if (data.success) {
                    showResults(data);
                    showSuccess(data.message);
                } else {
                    showError(data.message);
                }
            })
            .catch(error => {
                showLoading(false);
                showError('–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞: ' + error.message);
            });
        }

        function showResults(data) {
            const section = document.getElementById('resultsSection');
            section.classList.add('show');
            
            // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            showStats(data);
        }

        function showStats(data) {
            const statsGrid = document.getElementById('statsGrid');
            
            let html = `
                <div class="stat-card">
                    <h4>–°–æ–∑–¥–∞–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤</h4>
                    <div class="value">${data.total_forecasts}</div>
                </div>
                <div class="stat-card">
                    <h4>–ü–µ—Ä–∏–æ–¥–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞</h4>
                    <div class="value">${data.settings.periods}</div>
                </div>
                <div class="stat-card">
                    <h4>–ú–µ—Ç–æ–¥</h4>
                    <div class="value">${data.settings.method === 'random_forest' ? 'Random Forest' : '–õ–∏–Ω–µ–π–Ω—ã–π'}</div>
                </div>
            `;
            
            statsGrid.innerHTML = html;
        }

        function downloadResults() {
            if (!sessionId) return;
            
            window.open(`/download/${sessionId}`, '_blank');
        }

        function showLoading(show) {
            const loading = document.getElementById('loading');
            const btn = document.getElementById('forecastBtn');
            
            if (show) {
                loading.classList.add('show');
                btn.disabled = true;
            } else {
                loading.classList.remove('show');
                btn.disabled = false;
            }
        }

        function showError(message) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error';
            errorDiv.textContent = message;
            
            const container = document.querySelector('.main-content');
            container.insertBefore(errorDiv, container.firstChild);
            
            setTimeout(() => {
                errorDiv.remove();
            }, 5000);
        }

        function showSuccess(message) {
            const successDiv = document.createElement('div');
            successDiv.className = 'success';
            successDiv.textContent = message;
            
            const container = document.querySelector('.main-content');
            container.insertBefore(successDiv, container.firstChild);
            
            setTimeout(() => {
                successDiv.remove();
            }, 3000);
        }
    </script>
</body>
</html>
    """)

@app.route('/upload', methods=['POST'])
def upload_file():
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞"""
    if 'file' not in request.files:
        return jsonify({'success': False, 'message': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'})
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'message': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'})
    
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        session_id = str(uuid.uuid4())
        filename = f"{session_id}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        success, message = forecast_app.load_data_from_file(filepath)
        
        if success:
            forecast_app.session_id = session_id
            data_info = forecast_app.get_data_info()
            
            # –û—á–∏—â–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è JSON
            import json
            data_info_json = json.dumps(data_info, default=str)
            data_info_clean = json.loads(data_info_json)
            
            return jsonify({
                'success': True, 
                'message': message,
                'session_id': session_id,
                'data_info': data_info_clean
            })
        else:
            return jsonify({'success': False, 'message': message})
    
    return jsonify({'success': False, 'message': '–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞'})

@app.route('/api/get_time_series_values/<session_id>')
def get_time_series_values(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    try:
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        if forecast_app.df is None:
            return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
        
        df = forecast_app.df
        
        # –ü–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ - –æ–Ω –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–¥–∞–Ω –≤ –∑–∞–ø—Ä–æ—Å–µ
        mapping_data = request.args.get('mapping')
        if not mapping_data:
            return jsonify({'success': False, 'message': '–ú–∞–ø–ø–∏–Ω–≥ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä mapping.'})
        
        import json as json_lib
        mapping = json_lib.loads(mapping_data)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
        time_fields = {}
        for col in mapping.get('columns', []):
            if col.get('time_series') and col.get('include'):
                time_series_type = col['time_series']
                col_name = col['name']
                time_fields[time_series_type] = col_name
        
        print(f"–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞: {time_fields}")
        
        time_series = []
        
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        if time_fields:
            group_cols = [col_name for col_name in time_fields.values() if col_name in df.columns]
            
            if not group_cols:
                return jsonify({'success': False, 'message': '–í—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö'})
            
            unique_combinations = df[group_cols].drop_duplicates().to_dict('records')
            
            print(f"–ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {len(unique_combinations)}")
            if unique_combinations:
                print(f"–ü–µ—Ä–≤–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è: {unique_combinations[0]}")
            
            for combo in unique_combinations:
                item = {}
                # –û–±—Ä–∞—Ç–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: col_name -> time_series_type
                for time_type, col_name in time_fields.items():
                    value = combo.get(col_name)
                    if pd.notna(value) and value != '':
                        item[time_type] = value
                
                if item:
                    time_series.append(item)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≥–æ–¥—É
        if time_series:
            time_series.sort(key=lambda x: (x.get('year', 0), x.get('month', 0)))
        
        print(f"–í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤: {len(time_series)}")
        if time_series:
            print(f"–ü–µ—Ä–≤—ã–π —Ä—è–¥: {time_series[0]}")
        
        return jsonify({
            'success': True,
            'time_series': time_series,
            'time_fields': time_fields
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/get_metric_time_series/<session_id>')
def get_metric_time_series(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ä—è–¥–∞–º"""
    try:
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        if forecast_app.df is None:
            return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
        
        metric = request.args.get('metric')
        if not metric:
            return jsonify({'success': False, 'message': '–ú–µ—Ç—Ä–∏–∫–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'})
        
        df = forecast_app.df
        
        if metric not in df.columns:
            return jsonify({'success': False, 'message': f'–ú–µ—Ç—Ä–∏–∫–∞ {metric} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è (year –∏ month)
        year_field = None
        month_field = None
        
        for col in df.columns:
            if 'year' in col.lower() and not year_field:
                year_field = col
            if 'month' in col.lower() and not month_field:
                month_field = col
        
        if not year_field:
            return jsonify({'success': False, 'message': '–ü–æ–ª–µ –≥–æ–¥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'})
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª–µ –º–µ—Å—è—Ü–∞, –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –≥–æ–¥—É –∏ –º–µ—Å—è—Ü—É
        if month_field:
            # –°–æ–∑–¥–∞–µ–º —Å–æ—Å—Ç–∞–≤–Ω–æ–π –∫–ª—é—á –≥–æ–¥-–º–µ—Å—è—Ü
            df_copy = df.copy()
            df_copy['year_month'] = df_copy[year_field].astype(str) + '-' + df_copy[month_field].astype(str).str.zfill(2)
            
            aggregated = df_copy.groupby(['year_month', year_field, month_field])[metric].sum().reset_index()
            aggregated = aggregated.sort_values([year_field, month_field])
            
            labels = aggregated['year_month'].tolist()
            values = aggregated[metric].tolist()
        else:
            # –¢–æ–ª—å–∫–æ –ø–æ –≥–æ–¥–∞–º
            aggregated = df.groupby(year_field)[metric].sum().reset_index()
            aggregated = aggregated.sort_values(year_field)
            
            labels = aggregated[year_field].astype(str).tolist()
            values = aggregated[metric].tolist()
        
        return jsonify({
            'success': True,
            'data': {
                'labels': labels,
                'values': values,
                'metric': metric
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/save_forecast_settings', methods=['POST'])
def save_forecast_settings():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        
        if not session_id:
            return jsonify({'success': False, 'message': 'Session ID –Ω–µ —É–∫–∞–∑–∞–Ω'})
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ —Å–µ—Å—Å–∏—é
        forecast_settings = {
            'metric': data.get('metric'),
            'forecast_months': data.get('forecast_months', 0),
            'forecast_periods': data.get('forecast_periods', []),
            'time_series_config': data.get('time_series_config', {}),
            'created_at': datetime.now().isoformat()
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        if not hasattr(forecast_app, 'forecast_settings'):
            forecast_app.forecast_settings = {}
        
        forecast_app.forecast_settings[session_id] = forecast_settings
        
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")
        print(f"   –ú–µ—Ç—Ä–∏–∫–∞: {forecast_settings['metric']}")
        print(f"   –ì–æ—Ä–∏–∑–æ–Ω—Ç: {forecast_settings['forecast_months']} –º–µ—Å—è—Ü–µ–≤")
        print(f"   –ü—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤: {len(forecast_settings['forecast_periods'])}")
        
        return jsonify({
            'success': True,
            'message': '–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã'
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/get_forecast_settings/<session_id>')
def get_forecast_settings(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    try:
        if not hasattr(forecast_app, 'forecast_settings') or session_id not in forecast_app.forecast_settings:
            return jsonify({'success': False, 'message': '–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
        
        settings = forecast_app.forecast_settings[session_id]
        
        return jsonify({
            'success': True,
            'settings': settings
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/train_models', methods=['POST'])
def train_models():
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        if forecast_app.df is None:
            return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
        
        metric = data.get('metric')
        models_to_train = data.get('models', [])
        test_size = data.get('test_size', 0.2)
        
        print(f"\nüéØ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô:", flush=True)
        print(f"   –ú–µ—Ç—Ä–∏–∫–∞: {metric}", flush=True)
        print(f"   –ú–æ–¥–µ–ª–∏: {models_to_train}", flush=True)
        print(f"   –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {test_size * 100}%", flush=True)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = forecast_app.df
        
        # –ü–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥
        mapping_config = data.get('mapping')
        if not mapping_config and hasattr(forecast_app, 'mapping_config'):
            mapping_config = forecast_app.mapping_config
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è –∏ –ø–æ–ª—è —Å—Ä–µ–∑–æ–≤ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
        year_col = None
        month_col = None
        slice_cols = []
        
        if mapping_config and mapping_config.get('columns'):
            for col_config in mapping_config['columns']:
                if col_config.get('time_series') == 'year':
                    year_col = col_config['name']
                elif col_config.get('time_series') == 'month':
                    month_col = col_config['name']
                elif col_config.get('role') == 'dimension' and not col_config.get('time_series'):
                    slice_cols.append(col_config['name'])
        
        # Fallback: –ø–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
        if not year_col or not month_col:
            for col in df.columns:
                if 'year' in col.lower() and not year_col:
                    year_col = col
                if 'month' in col.lower() and not month_col:
                    month_col = col
        
        if not year_col or not month_col or metric not in df.columns:
            return jsonify({'success': False, 'message': '–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
        
        print(f"   üìä –ü–æ–ª—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:", flush=True)
        print(f"      –í—Ä–µ–º–µ–Ω–Ω—ã–µ: {year_col}, {month_col}", flush=True)
        print(f"      –°—Ä–µ–∑—ã: {slice_cols}", flush=True)
        print(f"      –ú–µ—Ç—Ä–∏–∫–∞: {metric}", flush=True)
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥–æ–¥—É-–º–µ—Å—è—Ü—É + —Å—Ä–µ–∑—ã
        groupby_cols = [year_col, month_col] + slice_cols
        df_agg = df.groupby(groupby_cols)[metric].sum().reset_index()
        df_agg = df_agg.sort_values([year_col, month_col])
        
        print(f"   üìä –ü–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {len(df_agg)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π", flush=True)
        
        results = {}
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ä–µ–∑—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥ (—Å—Ä–µ–∑—ã –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏)
        if slice_cols:
            print(f"   üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å–æ —Å—Ä–µ–∑–∞–º–∏ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏...", flush=True)
            print(f"   üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å—Ä–µ–∑–æ–≤: {len(df_agg)}", flush=True)
            
            # –û–±—É—á–∞–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
            for model_name in models_to_train:
                print(f"\nüìä –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}", flush=True)
                
                try:
                    if model_name == 'prophet':
                        model_result = train_prophet_with_slices(df_agg, metric, year_col, month_col, slice_cols, test_size)
                    elif model_name == 'random_forest':
                        model_result = train_random_forest_with_slices(df_agg, metric, year_col, month_col, slice_cols, test_size)
                    elif model_name == 'random_forest_hierarchy':
                        model_result = train_random_forest_hierarchy(df_agg, metric, year_col, month_col, slice_cols, test_size)
                    elif model_name == 'arima':
                        print(f"   ‚ö†Ô∏è ARIMA –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å–æ —Å—Ä–µ–∑–∞–º–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", flush=True)
                        continue
                    else:
                        print(f"   ‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å {model_name}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º", flush=True)
                        continue
                    
                    results[model_name] = model_result
                    
                    # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
                    if 'metrics_before_reconciliation' in model_result:
                        improvement = model_result.get('reconciliation_improvement', 0)
                        print(f"   ‚úÖ {model_name}: MAPE = {model_result['metrics']['mape']:.2f}% (—É–ª—É—á—à–µ–Ω–∏–µ: {improvement:.2f}%)", flush=True)
                    else:
                        print(f"   ‚úÖ {model_name}: MAPE = {model_result['metrics']['mape']:.2f}%", flush=True)
                    
                except Exception as e:
                    import traceback
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {model_name}: {e}", flush=True)
                    traceback.print_exc()
                    continue
        
        else:
            # –ù–µ—Ç —Å—Ä–µ–∑–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É (–æ–¥–∏–Ω –æ–±—â–∏–π –ø—Ä–æ–≥–Ω–æ–∑)
            print(f"   üìä –ù–µ—Ç —Å—Ä–µ–∑–æ–≤, –æ–±—É—á–∞–µ–º –Ω–∞ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            
            df_agg['period'] = df_agg[year_col].astype(str) + '-' + df_agg[month_col].astype(str).str.zfill(2)
            
            print(f"   –í—Å–µ–≥–æ –ø–µ—Ä–∏–æ–¥–æ–≤: {len(df_agg)}")
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é –≤—ã–±–æ—Ä–∫–∏
            split_index = int(len(df_agg) * (1 - test_size))
            train_df = df_agg[:split_index]
            test_df = df_agg[split_index:]
            
            print(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(train_df)} –ø–µ—Ä–∏–æ–¥–æ–≤")
            print(f"   –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(test_df)} –ø–µ—Ä–∏–æ–¥–æ–≤")
            
            for model_name in models_to_train:
                print(f"\nüìä –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
                
                try:
                    if model_name == 'arima':
                        model_result = train_arima_model(train_df, test_df, metric)
                    elif model_name == 'prophet':
                        model_result = train_prophet_model(train_df, test_df, metric, year_col, month_col)
                    elif model_name == 'random_forest':
                        model_result = train_random_forest_model(train_df, test_df, metric, year_col, month_col)
                    else:
                        continue
                    
                    results[model_name] = model_result
                    print(f"   ‚úÖ {model_name}: MAPE = {model_result['metrics']['mape']:.2f}%")
                    
                except Exception as e:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {model_name}: {e}")
                    continue
        
        if not results:
            return jsonify({'success': False, 'message': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω—É –º–æ–¥–µ–ª—å'})
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        if not hasattr(forecast_app, 'training_results'):
            forecast_app.training_results = {}
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Å –º–æ–¥–µ–ª—è–º–∏) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
        forecast_app.training_results[session_id] = results
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–ª–∏–µ–Ω—Ç—É (–±–µ–∑ –æ–±—ä–µ–∫—Ç–æ–≤ –º–æ–¥–µ–ª–∏)
        results_for_client = {}
        for model_name, model_data in results.items():
            results_for_client[model_name] = {
                'metrics': model_data['metrics'],
                'validation_data': model_data['validation_data'],
                'detailed_validation': model_data.get('detailed_validation', []),
                'slice_cols': model_data.get('slice_cols', [])
            }
        
        return jsonify({
            'success': True,
            'results': results_for_client
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/generate_forecast', methods=['POST'])
def generate_forecast():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        selected_model = data.get('model')
        mapping_from_request = data.get('mapping')  # –ü–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        if forecast_app.df is None:
            return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
        if not hasattr(forecast_app, 'forecast_settings') or session_id not in forecast_app.forecast_settings:
            return jsonify({'success': False, 'message': '–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
        
        settings = forecast_app.forecast_settings[session_id]
        metric = settings['metric']
        forecast_periods = settings['forecast_periods']
        
        # –ü–æ–ª—É—á–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –∏–∑ –∑–∞–ø—Ä–æ—Å–∞)
        mapping_config = None
        if mapping_from_request:
            mapping_config = mapping_from_request
            print("   ‚úÖ –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω –∏–∑ –∑–∞–ø—Ä–æ—Å–∞", flush=True)
        elif hasattr(forecast_app, 'mapping_config'):
            mapping_config = forecast_app.mapping_config
            print("   ‚úÖ –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª—É—á–µ–Ω –∏–∑ forecast_app", flush=True)
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
            import json
            project_file = f'projects/{session_id}.json'
            if os.path.exists(project_file):
                with open(project_file, 'r', encoding='utf-8') as f:
                    project_data = json.load(f)
                    mapping_config = project_data.get('data_mapping', {})
                    print("   ‚úÖ –ú–∞–ø–ø–∏–Ω–≥ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞ –ø—Ä–æ–µ–∫—Ç–∞", flush=True)
        
        if not mapping_config or not mapping_config.get('columns'):
            print("   ‚ö†Ô∏è –ú–∞–ø–ø–∏–Ω–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –±–∞–∑–æ–≤—ã–π –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫", flush=True)
            mapping_config = {'columns': []}
        
        print(f"\nüöÄ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–†–û–ì–ù–û–ó–ê:", flush=True)
        print(f"   –ú–æ–¥–µ–ª—å: {selected_model}", flush=True)
        print(f"   –ú–µ—Ç—Ä–∏–∫–∞: {metric}", flush=True)
        print(f"   –ü—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤: {len(forecast_periods)}", flush=True)
        
        # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
        if hasattr(forecast_app, 'forecast_results') and session_id in forecast_app.forecast_results:
            print(f"   üóëÔ∏è –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –∏–∑ –∫—ç—à–∞", flush=True)
            del forecast_app.forecast_results[session_id]
        else:
            print(f"   ‚ÑπÔ∏è –°—Ç–∞—Ä–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π", flush=True)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
        df = forecast_app.df
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–æ–ª—è –∏ –ø–æ–ª—è —Å—Ä–µ–∑–æ–≤ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
        year_col = None
        month_col = None
        slice_cols = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–ª–µ–π
        if mapping_config and mapping_config.get('columns'):
            for col_config in mapping_config['columns']:
                if col_config.get('time_series') == 'year':
                    year_col = col_config['name']
                elif col_config.get('time_series') == 'month':
                    month_col = col_config['name']
                elif col_config.get('role') == 'dimension' and not col_config.get('time_series'):
                    # –≠—Ç–æ –ø–æ–ª–µ —Å—Ä–µ–∑–∞
                    slice_cols.append(col_config['name'])
        
        # Fallback: –ø–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
        if not year_col or not month_col:
            for col in df.columns:
                if 'year' in col.lower() and not year_col:
                    year_col = col
                if 'month' in col.lower() and not month_col:
                    month_col = col
        
        if not year_col or not month_col or metric not in df.columns:
            return jsonify({'success': False, 'message': '–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
        
        print(f"   üìä –ü–æ–ª—è –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞:", flush=True)
        print(f"      –í—Ä–µ–º–µ–Ω–Ω—ã–µ: {year_col}, {month_col}", flush=True)
        print(f"      –°—Ä–µ–∑—ã: {slice_cols}", flush=True)
        print(f"      –ú–µ—Ç—Ä–∏–∫–∞: {metric}", flush=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–µ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º!)
        # –î–æ–±–∞–≤–ª—è–µ–º is_forecast = False –∫–æ –≤—Å–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º
        df['is_forecast'] = False
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –ø–æ–ª—è–º + —Å—Ä–µ–∑–∞–º
        groupby_cols = [year_col, month_col] + slice_cols
        df_agg = df.groupby(groupby_cols)[metric].sum().reset_index()
        df_agg = df_agg.sort_values([year_col, month_col])
        
        print(f"   üìä –ü–æ—Å–ª–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏: {len(df_agg)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π", flush=True)
        print(f"   üìä –ü–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏:", flush=True)
        print(df_agg.head(3).to_dict('records'), flush=True)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
        forecast_months = []
        for period in forecast_periods:
            for month in period['months']:
                forecast_months.append({
                    'year': period['year'],
                    'month': month
                })
        
        print(f"   –í—Å–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö –º–µ—Å—è—Ü–µ–≤: {len(forecast_months)}", flush=True)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
        all_metrics = [col['name'] for col in mapping_config.get('columns', []) if col.get('role') == 'metric']
        print(f"   üìä –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏: {all_metrics}", flush=True)
        print(f"   üéØ –ú–µ—Ç—Ä–∏–∫–∞ —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º: {metric}", flush=True)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ä–µ–∑—ã - —Å—Ç—Ä–æ–∏–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
        if slice_cols:
            print(f"   üîÑ –°—Ç—Ä–æ–∏–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤...", flush=True)
            
            # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
            unique_slices = df_agg[slice_cols].drop_duplicates().to_dict('records')
            print(f"   üìä –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å—Ä–µ–∑–æ–≤: {len(unique_slices)}", flush=True)
            print(f"   üìä –ü–µ—Ä–≤—ã–µ 3 –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏:", unique_slices[:3], flush=True)
            
            forecast_rows = []
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è random_forest_hierarchy
            if selected_model == 'random_forest_hierarchy':
                print(f"   üèóÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Random Forest Hierarchy - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö —Å—Ä–µ–∑–æ–≤ —Å—Ä–∞–∑—É", flush=True)
                
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
                if not hasattr(forecast_app, 'training_results') or session_id not in forecast_app.training_results:
                    return jsonify({'success': False, 'message': '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.'})
                
                trained_model_data = forecast_app.training_results[session_id].get('random_forest_hierarchy')
                if not trained_model_data:
                    return jsonify({'success': False, 'message': 'Random Forest Hierarchy –Ω–µ –æ–±—É—á–µ–Ω–∞'})
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Å—Ä–∞–∑—É
                try:
                    all_forecasts_detailed = generate_random_forest_hierarchy_forecast_detailed(
                        df_agg, metric, year_col, month_col, slice_cols, forecast_months, trained_model_data
                    )
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ forecast_rows
                    for forecast_dict in all_forecasts_detailed:
                        forecast_row = {}
                        forecast_row[year_col] = forecast_dict['year']
                        forecast_row[month_col] = forecast_dict['month']
                        
                        # –ö–æ–ø–∏—Ä—É–µ–º —Å—Ä–µ–∑—ã
                        for slice_col in slice_cols:
                            forecast_row[slice_col] = forecast_dict[slice_col]
                        
                        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫—É
                        forecast_row[metric] = forecast_dict['predicted']
                        for other_metric in all_metrics:
                            if other_metric != metric:
                                forecast_row[other_metric] = 0
                        
                        forecast_row['is_forecast'] = True
                        forecast_row['Quarter'] = f'Q{(forecast_dict["month"]-1)//3 + 1}'
                        forecast_row['Halfyear'] = 'H1' if forecast_dict['month'] <= 6 else 'H2'
                        
                        forecast_rows.append(forecast_row)
                    
                    print(f"   ‚úÖ Random Forest Hierarchy: —Å–æ–∑–¥–∞–Ω–æ {len(forecast_rows)} –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö —Å—Ç—Ä–æ–∫", flush=True)
                    
                except Exception as e:
                    print(f"   ‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ Random Forest Hierarchy: {e}", flush=True)
                    import traceback
                    traceback.print_exc()
                    return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})
            
            elif selected_model == 'random_forest':
                # Random Forest —Ç–æ–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å —Å–æ –≤—Å–µ–º–∏ —Å—Ä–µ–∑–∞–º–∏
                print(f"   üå≤ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Random Forest - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –≤—Å–µ—Ö —Å—Ä–µ–∑–æ–≤", flush=True)
                
                if not hasattr(forecast_app, 'training_results') or session_id not in forecast_app.training_results:
                    return jsonify({'success': False, 'message': '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.'})
                
                trained_model_data = forecast_app.training_results[session_id].get('random_forest')
                if not trained_model_data:
                    return jsonify({'success': False, 'message': 'Random Forest –Ω–µ –æ–±—É—á–µ–Ω–∞'})
                
                model = trained_model_data.get('model')
                label_encoders = trained_model_data.get('label_encoders', {})
                
                if not model:
                    return jsonify({'success': False, 'message': '–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
                for slice_combination in unique_slices:
                    for fm in forecast_months:
                        forecast_row = {
                            year_col: fm['year'],
                            month_col: fm['month']
                        }
                        
                        # –ö–æ–¥–∏—Ä—É–µ–º —Å—Ä–µ–∑—ã
                        for slice_col in slice_cols:
                            forecast_row[slice_col] = slice_combination[slice_col]
                            encoded_col = f'{slice_col}_encoded'
                            if encoded_col in label_encoders:
                                le = label_encoders[encoded_col]
                                value = slice_combination[slice_col]
                                try:
                                    encoded_value = le.transform([value if value in le.classes_ else 'unknown'])[0]
                                except:
                                    encoded_value = 0
                                forecast_row[encoded_col] = encoded_value
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        feature_cols = [year_col, month_col] + [f'{col}_encoded' for col in slice_cols]
                        X_forecast = np.array([[forecast_row.get(col, 0) for col in feature_cols]])
                        
                        # –ü—Ä–æ–≥–Ω–æ–∑
                        predicted_value = model.predict(X_forecast)[0]
                        
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—É—é —Å—Ç—Ä–æ–∫—É
                        final_row = {}
                        final_row[year_col] = fm['year']
                        final_row[month_col] = fm['month']
                        
                        for slice_col in slice_cols:
                            final_row[slice_col] = slice_combination[slice_col]
                        
                        final_row[metric] = predicted_value
                        for other_metric in all_metrics:
                            if other_metric != metric:
                                final_row[other_metric] = 0
                        
                        final_row['is_forecast'] = True
                        final_row['Quarter'] = f'Q{(fm["month"]-1)//3 + 1}'
                        final_row['Halfyear'] = 'H1' if fm['month'] <= 6 else 'H2'
                        
                        forecast_rows.append(final_row)
                
                print(f"   ‚úÖ Random Forest: —Å–æ–∑–¥–∞–Ω–æ {len(forecast_rows)} –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö —Å—Ç—Ä–æ–∫", flush=True)
            
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π (prophet, arima) - —Ü–∏–∫–ª –ø–æ —Å—Ä–µ–∑–∞–º —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
                print(f"   ‚ö†Ô∏è –ú–æ–¥–µ–ª—å {selected_model} –±—É–¥–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—Ä–µ–∑–∞", flush=True)
                
                for slice_combination in unique_slices:
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
                    mask = pd.Series([True] * len(df_agg))
                    for slice_col in slice_cols:
                        mask &= (df_agg[slice_col] == slice_combination[slice_col])
                    
                    df_slice = df_agg[mask].copy()
                    
                    if len(df_slice) < 10:
                        continue
                    
                    # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —ç—Ç–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
                    try:
                        if selected_model == 'arima':
                            slice_forecast = generate_arima_forecast(df_slice, metric, len(forecast_months))
                        elif selected_model == 'prophet':
                            slice_forecast = generate_prophet_forecast(df_slice, metric, year_col, month_col, forecast_months)
                        else:
                            continue
                        
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —ç—Ç–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ —Å—Ä–µ–∑–æ–≤
                        for i, month_data in enumerate(forecast_months):
                            forecast_row = {}
                            forecast_row[year_col] = month_data['year']
                            forecast_row[month_col] = month_data['month']
                            
                            # –ö–æ–ø–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ä–µ–∑–æ–≤
                            for slice_col in slice_cols:
                                forecast_row[slice_col] = slice_combination[slice_col]
                            
                            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
                            forecast_row[metric] = slice_forecast[i]
                            for other_metric in all_metrics:
                                if other_metric != metric:
                                    forecast_row[other_metric] = 0
                            
                            forecast_row['is_forecast'] = True
                            forecast_row['Quarter'] = f'Q{(month_data["month"]-1)//3 + 1}'
                            forecast_row['Halfyear'] = 'H1' if month_data['month'] <= 6 else 'H2'
                            
                            forecast_rows.append(forecast_row)
                    
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–ª—è {slice_combination}: {e}", flush=True)
                        continue
            
            forecast_df = pd.DataFrame(forecast_rows)
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö —Å—Ç—Ä–æ–∫: {len(forecast_df)}", flush=True)
        else:
            # –ù–µ—Ç —Å—Ä–µ–∑–æ–≤ - —Å—Ç—Ä–æ–∏–º –æ–¥–∏–Ω –æ–±—â–∏–π –ø—Ä–æ–≥–Ω–æ–∑ (—Å—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞)
            print(f"   üìä –ù–µ—Ç —Å—Ä–µ–∑–æ–≤, —Å—Ç—Ä–æ–∏–º –æ–±—â–∏–π –ø—Ä–æ–≥–Ω–æ–∑", flush=True)
            
            if selected_model == 'arima':
                forecast_values = generate_arima_forecast(df_agg, metric, len(forecast_months))
            elif selected_model == 'prophet':
                forecast_values = generate_prophet_forecast(df_agg, metric, year_col, month_col, forecast_months)
            elif selected_model == 'random_forest':
                forecast_values = generate_random_forest_forecast(df_agg, metric, year_col, month_col, forecast_months)
            else:
                return jsonify({'success': False, 'message': f'–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {selected_model}'})
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            forecast_rows = []
            last_row = df.iloc[-1].to_dict()
            
            for i, month_data in enumerate(forecast_months):
                forecast_row = last_row.copy()
                forecast_row[year_col] = month_data['year']
                forecast_row[month_col] = month_data['month']
                forecast_row[metric] = forecast_values[i]
                
                for other_metric in all_metrics:
                    if other_metric != metric:
                        forecast_row[other_metric] = 0
                
                forecast_row['is_forecast'] = True
                forecast_row['Quarter'] = f'Q{(month_data["month"]-1)//3 + 1}'
                forecast_row['Halfyear'] = 'H1' if month_data['month'] <= 6 else 'H2'
                
                forecast_rows.append(forecast_row)
            
            forecast_df = pd.DataFrame(forecast_rows)
        
        # –î–æ–±–∞–≤–ª—è–µ–º Quarter –∏ Halfyear –∫ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        if 'Quarter' not in df.columns:
            df['Quarter'] = df[month_col].apply(lambda m: f'Q{(m-1)//3 + 1}')
        if 'Halfyear' not in df.columns:
            df['Halfyear'] = df[month_col].apply(lambda m: 'H1' if m <= 6 else 'H2')
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å–æ –≤—Å–µ–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏ + –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        combined_df = pd.concat([df, forecast_df], ignore_index=True)
        
        print(f"   üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {len(df)} —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö + {len(forecast_df)} –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã—Ö = {len(combined_df)} —Å—Ç—Ä–æ–∫")
        
        print(f"   ‚úÖ –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(forecast_df)} –ø–µ—Ä–∏–æ–¥–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ –ø–∞–º—è—Ç—å
        if not hasattr(forecast_app, 'forecast_results'):
            forecast_app.forecast_results = {}
        
        forecast_app.forecast_results[session_id] = {
            'model': selected_model,
            'metric': metric,
            'combined_data': combined_df.to_dict('records'),
            'forecast_only': forecast_df.to_dict('records'),
            'historical_periods': len(df),
            'forecast_periods': len(forecast_df)
        }
        
        # –§–∏–∑–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª—ã
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            forecast_dir = 'results'
            if not os.path.exists(forecast_dir):
                os.makedirs(forecast_dir)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ñ–∞–∫—Ç + –ø—Ä–æ–≥–Ω–æ–∑)
            combined_filename = f'forecast_combined_{session_id}.csv'
            combined_path = os.path.join(forecast_dir, combined_filename)
            combined_df.to_csv(combined_path, index=False, encoding='utf-8')
            print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {combined_path}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≥–Ω–æ–∑–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            forecast_filename = f'forecast_only_{session_id}.csv'
            forecast_path = os.path.join(forecast_dir, forecast_filename)
            forecast_df.to_csv(forecast_path, index=False, encoding='utf-8')
            print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∞–π–ª –ø—Ä–æ–≥–Ω–æ–∑–∞: {forecast_path}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ forecast_results
            forecast_app.forecast_results[session_id]['combined_file'] = combined_path
            forecast_app.forecast_results[session_id]['forecast_file'] = forecast_path
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}")
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É –¥–∞–∂–µ –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
        
        return jsonify({
            'success': True,
            'message': '–ü—Ä–æ–≥–Ω–æ–∑ —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω',
            'files': {
                'combined': combined_filename if 'combined_filename' in locals() else None,
                'forecast_only': forecast_filename if 'forecast_filename' in locals() else None
            }
        })
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/get_forecast_results/<session_id>')
def get_forecast_results(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    try:
        if not hasattr(forecast_app, 'forecast_results') or session_id not in forecast_app.forecast_results:
            return jsonify({'success': False, 'message': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
        
        results = forecast_app.forecast_results[session_id]
        
        return jsonify({
            'success': True,
            'forecast_data': {
                'raw_data': results['combined_data'],
                'pivot_data': None  # –ë—É–¥–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–µ
            },
            'info': {
                'model': results['model'],
                'metric': results['metric'],
                'historical_periods': results['historical_periods'],
                'forecast_periods': results['forecast_periods'],
                'files': {
                    'combined': results.get('combined_file'),
                    'forecast_only': results.get('forecast_file')
                }
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/export_forecast/<session_id>')
def export_forecast(session_id):
    """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∞ –≤ CSV"""
    try:
        if not hasattr(forecast_app, 'forecast_results') or session_id not in forecast_app.forecast_results:
            return jsonify({'success': False, 'message': '–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'})
        
        results = forecast_app.forecast_results[session_id]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if 'combined_file' in results and os.path.exists(results['combined_file']):
            return send_file(
                results['combined_file'],
                as_attachment=True,
                download_name=f"forecast_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            )
        else:
            return jsonify({'success': False, 'message': '–§–∞–π–ª –ø—Ä–æ–≥–Ω–æ–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω'})
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞: {str(e)}'})

@app.route('/api/update_file', methods=['POST'])
def update_file():
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º session_id"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'message': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'})
        
        file = request.files['file']
        old_session_id = request.form.get('session_id')
        
        if file.filename == '':
            return jsonify({'success': False, 'message': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'})
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ session_id –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –º–∞–ø–ø–∏–Ω–≥–∞
            session_id = old_session_id if old_session_id else str(uuid.uuid4())
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —Å —Ç–µ–º –∂–µ session_id
            upload_folder = app.config['UPLOAD_FOLDER']
            if old_session_id:
                old_files = [f for f in os.listdir(upload_folder) if f.startswith(old_session_id)]
                for old_file in old_files:
                    try:
                        os.remove(os.path.join(upload_folder, old_file))
                        print(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {old_file}")
                    except:
                        pass
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª —Å —Ç–µ–º –∂–µ session_id
            new_filename = f"{session_id}_{filename}"
            filepath = os.path.join(upload_folder, new_filename)
            file.save(filepath)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            success, message = forecast_app.load_data_from_file(filepath)
            
            if success:
                forecast_app.session_id = session_id
                data_info = forecast_app.get_data_info()
                
                return jsonify({
                    'success': True,
                    'message': '–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω',
                    'session_id': session_id,
                    'rows': data_info['shape'][0],
                    'columns': data_info['shape'][1],
                    'filename': filename
                })
            else:
                return jsonify({'success': False, 'message': message})
        
        return jsonify({'success': False, 'message': '–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞'})
        
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}'})

@app.route('/forecast_api', methods=['POST'])
def forecast_api():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞"""
    try:
        config = request.json
        print(f"DEBUG: –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ: {config}")
        
        # –ü–æ–ª—É—á–∞–µ–º session_id –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        session_id = config.get('session_id')
        if not session_id or forecast_app.session_id != session_id:
            return jsonify({'success': False, 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'})
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if forecast_app.df is None:
            return jsonify({'success': False, 'message': '–î–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã'})
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        mapping_data = config.get('mapping_data')
        if mapping_data:
            mapping = json.loads(mapping_data)
            print(f"DEBUG: –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞: {mapping}")
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            mapping = {
                'year': config.get('year_column', 0),
                'month': config.get('month_column', 1)
            }
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫
        forecast_app.set_data_mapping(mapping)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
        forecast_config = {
            'periods': config.get('periods', 4),
            'method': config.get('method', 'random_forest'),
            'target_metric': config.get('target_metric'),
            'enable_cascade': config.get('enable_cascade', True)
        }
        
        print(f"DEBUG: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞: {forecast_config}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑
        success, message = forecast_app.run_cascaded_forecast(forecast_config)
        
        if success:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            forecast_app.save_results(forecast_app.session_id)
            
            return jsonify({
                'success': True,
                'message': message,
                'total_forecasts': forecast_app.forecast_results.get('total_forecasts', 0),
                'settings': forecast_config
            })
        else:
            return jsonify({'success': False, 'message': message})
            
    except Exception as e:
        print(f"ERROR: –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞: {e}")
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}'})

@app.route('/download/<session_id>')
def download_results(session_id):
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    filename = f"cascaded_forecast_{session_id}.csv"
    filepath = os.path.join(app.config['RESULTS_FOLDER'], filename)
    
    if os.path.exists(filepath):
        return send_file(filepath, as_attachment=True, download_name=filename)
    else:
        return jsonify({'success': False, 'message': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'})

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ MARFOR –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    print("üìä –ö–∞—Å–∫–∞–¥–Ω–∞—è –º–æ–¥–µ–ª—å —Å Random Forest")
    print("üîß –í–ï–†–°–ò–Ø –ö–û–î–ê: 2.21.0 - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
    print("üåê –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:5001 –≤ –±—Ä–∞—É–∑–µ—Ä–µ")
    app.run(debug=True, host='0.0.0.0', port=5001)
